<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Clayton Blythe" />
        <meta name="copyright" content="Clayton Blythe" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="cs231n, python, notes, neural networks, CS231n, " />

<meta property="og:title" content="CS231n Lecture 4 Notes "/>
<meta property="og:url" content="http://68.40.128.255/cs231n-lecture-4-notes.html" />
<meta property="og:description" content="The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through …" />
<meta property="og:site_name" content="deepython.com" />
<meta property="og:article:author" content="Clayton Blythe" />
<meta property="og:article:published_time" content="2017-09-03T13:10:00-05:00" />
<meta name="twitter:title" content="CS231n Lecture 4 Notes ">
<meta name="twitter:description" content="The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through …">

        <title>CS231n Lecture 4 Notes  · deepython.com
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="http://68.40.128.255/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://68.40.128.255/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://68.40.128.255/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="http://68.40.128.255/theme/css/custom.css" media="screen">
        <link rel="shortcut icon" href="http://68.40.128.255/theme/images/favicon.ico" type="image/x-icon" type="image/png" />
        <link rel="icon" href="http://68.40.128.255/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" href="http://68.40.128.255/theme/images/apple-touch-icon.png"  type="image/png" />
        <link rel="apple-touch-icon" sizes="57x57" href="http://68.40.128.255/theme/images/apple-touch-icon-57x57.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="72x72" href="http://68.40.128.255/theme/images/apple-touch-icon-72x72.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="76x76" href="http://68.40.128.255/theme/images/apple-touch-icon-76x76.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="114x114" href="http://68.40.128.255/theme/images/apple-touch-icon-114x114.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="120x120" href="http://68.40.128.255/theme/images/apple-touch-icon-120x120.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="144x144" href="http://68.40.128.255/theme/images/apple-touch-icon-144x144.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="http://68.40.128.255/theme/images/apple-touch-icon-152x152.png" type="image/png" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="http://68.40.128.255/"><span class=site-name><img src="/theme/images/android-chrome-512x512.png" width="33" height="33">  <span style="color:#254601; font-size:17pt">  deepython.com </span> </span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="http://68.40.128.255">Home</a></li>
                            <li ><a href="http://68.40.128.255/categories.html">Categories</a></li>
                            <li ><a href="http://68.40.128.255/tags.html">Tags</a></li>
                            <li ><a href="http://68.40.128.255/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="http://68.40.128.255/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="http://68.40.128.255/cs231n-lecture-4-notes.html"> CS231n Lecture 4 Notes  </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            
            <p>The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through recursive application of the chain rule, that you might be familiar with from multivariable calculus. </p>
<p>Most of this section can be understood by reviewing the concept of how local derivatives can be calculated through the chain rule by using the output at that point and nearby gradients. The name "backpropagation" refers to how the chain rule is applied recursively backwards (i.e. backpropagating) through the circuit and can be thought of as gates communicating to each other, telling each other whether they want their outputs to increase or decrease in the aim of making the final output value higher. </p>
<p>So to reiterate, the <em>forward pass</em> computes values from input to output, and the <em>backward pass</em> starts at the end and recursively applies the chain rule to sequentially compute the gradients. As a result, the gradients can be thought of as flowing backwards through the circuit. </p>
<p>The interesting behavior is that to understand and calculate backpropagation, you only need local characteristics of the circuit such as output value of the gate and the local gradient of the inputs of a node with respect to the output value of that node. </p>
<p>The lecture then uses an example with the <a href="https://en.wikipedia.org/wiki/Activation_function">sigmoid activation function</a></p>
<p>Patterns in backward flow:
1. Add
2. Multiply
3. Maximum</p>
<p>The <em>add gate</em> always takes the gradient on its output and distributes it equally to all of its inputs, regardless of what the values were during the forward pass. </p>
<p>The <em>multiply gate</em> has local gradients as input values, and this is multiplied on its output during the chain rule.</p>
<p>The <em>max gate</em> routes the gradient, distributing the gradient to exactly one of its inputs. </p>
<p>Summary: This section provided intuition for what role gradients play in neural networks and how they relate to backpropagation. The section also how these gradients flow backwards through the "circuit", determining which parts components (weights and biases) should increase or decrease to force the final output higher. It also discussed the idea of <em>staged computation</em> for implementing backpropagation in an iterative fashion. The idea is to break up your function into modules to derive local gradients and then chain them. The key is to decompose expressions into stages such that you can
differentiate each stage independently, working through the circuit one step at a time. </p>
<p>The next section will start discussion neural networks and how backpropagation allows for efficiently computing the gradients of the connections with respect to a loss function. </p>
<p>Until next time,</p>
<h4>Clayton Blythe | <em>Deep Python</em></h4>
            
            
            <hr/>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2017-09-03T13:10:00-05:00">Sep 3, 2017</time>
            <h4>Category</h4>
            <a class="category-link" href="http://68.40.128.255/categories.html#cs231n-ref">CS231n</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="http://68.40.128.255/tags.html#cs231n-ref">cs231n
                    <span>3</span>
</a></li>
                <li><a href="http://68.40.128.255/tags.html#neural-networks-ref">neural networks
                    <span>4</span>
</a></li>
                <li><a href="http://68.40.128.255/tags.html#notes-ref">notes
                    <span>3</span>
</a></li>
                <li><a href="http://68.40.128.255/tags.html#python-ref">python
                    <span>8</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="http://linkedin.com/in/claytonblythe" title="My LinkedIn Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-linkedin sidebar-social-links"></i></a>
    <a href="http://github.com/claytonblythe" title="My Github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-license"><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">deepython.com</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://deepython.com" property="cc:attributionName" rel="cc:attributionURL">Clayton Blythe</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</li>
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>