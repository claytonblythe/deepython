{"pages":[{"title":"Lecture 4 Notes","text":"CS231n : Lecture 4 Notes The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradients of weights and biases through recursive application of the chain rule in multivariable calculus. Most of this section can be understood by reviewing the concept of computing derivatives through the chain rule. The name \"backpropagation\" is referring to how the chain rule is applied recursively backwards through the circuit and can be thought of as gates communicating to each other whether they want their outputs to increase or decrease, so as to make the final output value higher. The lecture then uses an example with the sigmoid activation function Patterns in backward flow: 1. Add 2. Multiply 3. Maximum The add gate always takes the gradient on its output and distributes it equally to all of its inputs, regardless of what thier values were during the forward pass. The multiply gate has local gradients as input values, and this is multiplied on its output during the chain rule. The max gate routes the gradient, distributing the gradient to exactly one of its inputs. Summary: This section provided intuition for what the gradients mean, and how they flow backwards through the circuit, determining which parts of the circuit (weights and biases) shoudl increase or decrease to force the final output higher. It also discussed staged computation for implementing backpropagation. The idea is to break up your function into modules to derive local gradients and then chain them. The key is to decompose expressions into stages such that you can differentiate each stage independently one step at a time. The next section will start discussion neural networks and how backpropagation allows for efficiently computing the gradients of the connections with respect to a loss function. Until next time, Clayton Blythe | Deep Python","tags":"CS231n","url":"lecture-4-notes.html"},{"title":"My Git Workflow","text":"Working Efficiently (a.k.a. Lazily) I think it is very important to reduce the amount of typing that one has to do to keep track of projects, experiments, and working with version control, especially across multiple devices. As such, I have developed a sytem that I think works pretty well, for managing Github respositories and projects directly from the command line. Though it is heavily personalized to my own Github profile and there are other tools out there like Hub, I decided to build my own. First off, I make a bash script called newRepo.sh which will create a new repository named after the first argument that I provide. So if I type \"newRepo pytorchTutorials\" then I will create a new github project called pytorchTutorials in my Github profile. This allows me to quickly create repos from the command line without having to go to the Github website, create a repository, and then clone it through the command line. My script uses the Github API, to create and clone the newly made repository with a specified structure for data, notebooks, figures, and scripts. The script is a work in progress still, and I am looking to make other aliases that will allow for creating private repositories and deleting them as well. Other useful git tools that I have made are aliases for cloning, commiting, and pushing changes to the remote repository. I have 'git status' as gs, 'git add --all' as gaa, and 'gcp \"message here\"' as an alias to commit all the added changes with a provided commit message, and then push the changes. This tends to speed up my workflow greatly, and I hope you can find them useful! Most of the aliases can be found in my dotfiles repository and the newRepo script can be found in my version_control repository : Until next time, Clayton Blythe | Deep Python","tags":"Git","url":"my-git-workflow.html"},{"title":"Spark MLlib Overview","text":"This is an overview of the Spark MLlib framework, Spark's scalable machine learning library consisting of common machine learning algorithms and utilities that include tools for classification, regression, clustering, collaborative filtering, dimensionality reduction, as well as providing underlying basic summary statistics. It also contains various utilities for doing linear algrebra, statistics, and general handling of data. MLlib uses the linear algebra package called Breeze, which depends on the netlib-java for optimized numerical processing. Spark MLlib is distinct from Spark ML, as it deals with RDD (Resilient Distributed Datasets) instead of DataFrames. RDD's are fundamental data structures of Spark, which are divided into logical partitions and distributed across different nodes of a cluster. Spark makes use of the concept of RDD to achieve faster and more efficient MapReduce operations. It is also fault tolerant as well as in-memory data processing, which is 10 to 100 times faster than network and Disk. Here is a broad overview of the capabilities of Spark MLlib: Basic Statistics Correlation computes the correlation matrix for the input Dataset of vectors, and the output will be a DataFrame that contains the correlation matrix of the column of vectors. Hypothesis Testing is possible thorugh a ChiSquare test to conduct a Pearson independence test for every feature against the label or target. For each feature, the feature label pairs are converted into a contingency matrix for which the Chi-squared statistic is computed. ML Pipelines Inspired by the scikit-learn project, MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline or workflow. DataFrame ML API uses DataFrame form Spark SQL as an ML dataset, which can hold a variety of data types. Transformer is an algorithm that can transform one DataFrame into another DataFrame (e.g. an ML model is a Transformer which transforms a DataFrame into a DataFrame with predictions). Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer (this would be a learning algorithm which produces a model) Pipeline chains multiple Transformers and Estimators together for a ML workflow. Feature Selection & Transformation TF-IDF (Term frequency-inverse document frequency) is a feature vectorization method used in text mining to reflec thte importance of a term to a document in the corpus. Word2Vec is an Estimator which takes sequences of words representing documents and trains a Word2VecModel, which maps each word to a unique fixed-size vector. CountVectorizer aim to convert a collection of text documents to vectors of token counts. Tokenizer is a simple class providing functionality for taking text and breaking it into individual terms (usually words), there is also RegexTokenizer which allows more advanced tokenization based on regex matching. StopWordsRemover takes an input of a sequence of strings and drops all the stop words from the input sequences. NGram takes an input of a sequence of strings and the parameter n is used to determine the number of terms in each n-gram. The output will be a sequence of n-grams where each n-gram is represented by a space-delimited string of n consecutive words. PCA is a statistical procedure that uses orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. Polynomial Expansion is the process of expanding your features into a polynomial space, which is formulated by an n-degree combination of original dimensions. OneHotEncoder allows for mapping a column of label indices to a column of binary vectors. This enables algorithms such as logistic regression to utilize categorical variables. VectorIndexer helps index categorical features in datasets of Vectors. It can allow algorithms such as Decision Trees and Tree Ensembles to treat categorical features appropriately, improving performance. Interaction is a Transformer which takes vector or double-valued columns and can generate their interactions. Normalizer is a Transformer which transforms a dataset of Vector rows, normalizing each Vector to have unit norm. It takes some parameter p, which uses the p-norm used for normalization. StandardScaler transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean. MinMaxScaler is often used to rescale a feature to a specific range like [0,1]. MaxAbsScaler transforms a dataset of Vector rows to a range of [-1,1]. Bucketizer transforms a column of continous features to a column of feature buckets. Imputer is a transformer that completes missing values in a dataset, either using the mean or the median. Feature Selectors VectorSlicer is a transformer that takes a feature vecotr and outputs a new feature vector with a sub-array of the original features. It is useful for extracting features from a vector column. RFormula selects columns specified by an R model formula, (~, ., +, etc.) ChiSqSelector uses Chi-Squared tests of independence to decide which features to use, from a fixed number of top features. LSH Algorithms like Bucketed Random Projection for Euclidian distance and MinHash for Jaccard Distance. Classification and Regression Logistic Regression is supported with summary statistics, as well as multinomial logistic regression. DecisionTreeClassifier is a tree based calssification and regression model and so is RandomForestClassificationModel and GBTClassificationModel MultilayerPerceptronClassifier is a classifier based on feedforward artificial neural networks, and it consists of fully connected layers that itulize a simoid logistic function and the output layer uses a softmax function. The number of nodes in the output layer corresponds to the number of classes to be classified. LinearSVC is a support vector machine that represents a hyperplane or set of hyperplanes in a high or infinite dimensional space that can be used for classification, regression, or other tasks. NaiveBayes allows for simple probabilistic classifiers on applying Bayes' theorem with strong (naive) independence assumptions between the features. For regression problems, LinearRegression and GeneralizedLinearRegression are supported. AFTSurvivalRegression employs an Accelerated failure time (AFT) model, which is a parametric survival regression model for censored data. It is a log-linear model for survival analysis and is easier to parallelize. Other methods like ensembles of decision trees, random forest, and gradient-boosted trees are supported. Until next time, Clayton Blythe | Deep Python","tags":"Spark","url":"spark-mllib-overview.html"},{"title":"Lecture 3 Notes","text":"CS231n : Lecture 3 Notes I have recently been making my way through the Stanford Computer Science 231n course. This particular lecture was about defining a loss function for how the Linear Classifier performs across all of the training data, and this in a sense quantifies how \"unhappy\" our scores are across the training data. The task then is to find a way to efficiently find the parameters (Weights and Biases) that minimize and optimize the loss function via some optimization algorithm like Gradient Descent. Loss Functions Multiclass SVM Loss Softmax Classifier: (Cross-Entropy Loss / Multinomial Logistic Regression) Multiclass SVM Loss : The average across all the differences of the scores between the correct class and incorrect classes with a constant of one added. 1/N * Sigma { ((Incorrect class score - Correct class score) + 1)} . Using a value of one here is arbitrary and really just determines what magnitude the weights can be. Here when we initialize the weights, they are chosen to be small numbers, so in this case the initial value for the loss will be 2. W values can be multiplied and they could be twice as large and achieve the same Loss (ignoring bias). Weight Regularization : A set of techniques to add objectives to the loss, to tradeoff between training error and generalization error. i.e. a trade off between bias and variance The most common form of regularization is L2 regularization, also known as weight decay. This pushes the weights to being smaller and more diffused across all pixels and features, which prevents overfitting, leading to better generalization performance. Therefore regularization loss is a new component that contributes to the overall loss, and is only a function of the weights, not your dataset. Including this weight regularization in the loss function that you are trying to minimize leads to weights that not only classify correctly but prefer diffuse weights, taking into account as much of the image as possible. Why would we want more evenly spread weights? This allows for taking in more parts and features of the input image into account. Softmax Loss : Softmax Loss is a different functional form for how loss is specified across scores. This assumes that the scores are unormalized log probabilities for each class. To get probabilities for each class, we take the exponentiated scores for each element divided by the sum of all exponentiated elements. So here we want to maximize the log likelihood, or for a loss function we want to minimize the negative log likelihood of the correct class. It turns out that maximizing this is more mathematically conducive than maximizing the negative probabilities themselves. For the example of classifying a cat, if the normalized probability of a cat class is .13 then the loss would be -log(.13)= .89, and we are trying to maximize this, where zero is the minimum and there is no bounded maximum. When we initialize weights we typically choose them to be very small, so there should be an initial loss of -log( 1 / number of classes), as the initial scores would be zero, then unormalized probabilities of 1 for every class, then the loss should be -log( 1 / # of classes ). As the model trains, the loss should move toward zero. Optimization occurs by finding the gradient of the loss function with respect to certain parameters, usually the weights for each class. In practice an analytic gradient is used, which is an exact, fast, but error-prone method. You often then do a gradient check, where you compare the numerical gradient which is usually approximate, slow, but easy to write compared to your analytic gradient. Stochastic Gradient Descent : This process is usually composed of two steps: 1. Find the weights gradient by evaluating the gradient of the loss function with respect to data, weights 2. Set new weights by multiplying step size (a.k.a. learning rate) by the gradient of the loss function with respect to weights, in the direction of the negative gradient. The gradient points in the direction of maximal increase, so the negative gradient will lead to minimizing the loss function, or at least moving toward some local or global minimum. Your learning rate / step size are an important hyperparameter for this. Mini-batch Gradient Descent : Instead of using all training samples for each iteration (finding the gradient of the loss function corresponding to all your training data), you can use a small batch size comprised of a small subset of your training data. Then you can get a good approximation of the gradient and use smaller step sizes rather than using a full-batch size for each iteration or epoch. Often this isn't a very significant hyperparameter to tune, but rather you choose this based on your GPU architecture and the constraints of your memory. The key is finding the appropriate learning rate to converge over time across epochs (iterations). The loss function can be thought of as an optimization problem in high-dimensional space, in which we are trying to reach the bottom of some high-dimensional valley. We start with some random initialization of weights and through iterative differentiation and adjustement we can reach the bottom. The next important concept to cover will be backprogation, essentially how to compute the gradient analytically using the chain rule. The advancements recently (since roughly 2012) of using these techniques for neural networks are that you do not have to hand-craft features regarding your images, but rather you can train your entire network and feature extraction without explicitly programming the structure of different features or objects into some rule-based recognition system. Here the networks can be trained all the way back to the raw pixels, which make them very powerful and flexible. Until next time, Clayton Blythe | Deep Python","tags":"CS231n","url":"lecture-3-notes.html"},{"title":"Deep Learning 101","text":"Deep Learning 101: A Brief Introduction So you want to learn about Deep Learning huh? Well I'm not sure I'm quite qualified yet, as I just started learning about this myself. But the best way to learn something is to try to teach it to other people, so here I am. I hope you find this post and blog useful. To begin our understanding of this field, we need to introduce the topic of machine learning. Machine Learning is the ability of a computer to aquire knowledge and make predictions through extracting latent patterns and information from data. Machine Learning is almost a form of applied statistics in which computers statistically estimate some function. Within machine learning, problems can usually be broken down into supervised learning and unsupervised learning . The former infers or approximates some function from labeled training data, where the function represents some relationship between input variables (often called features) and a labeled or known output value. In unsupervised learning, the task is to describe the hidden structure and properties of input data without explicitly being given labeled training data. It is within this realm of unsupervised machine learning that Deep Learning resides, and it will be the primary focus of this blog, Deep Python @ deepython.com . A couple fundamental concepts in deep learning are Artificial Neural Networks and Convolutional Neural Networks. Key concepts: * Artificial Neural Networks * Convolutional Recurrent Neural Networks (CNNs) Artificial Neural Networks are systems created by modern computing systems created to complete complex tasks such as image and sound recognition. They were inspired by traditional biological networks, which are adept at completing complex tasks like recognizing faces, understanding audible speech, or translating one written language into another. However these tasks are extermely difficult to formalize into traditional rule-based systems, and hence have been difficult to implement in the past. This is the most promising and conceptually difficult area of machine learning, as it requires utilizing linear algebra along with modern GPU architectures to create a complex network of connections, which allow computers to learn from experiences and solve problems through breaking tasks down into simpler, more manageable components. This is done by stacking several \"layers\" of mathematical operations and architectures on top of one another, hence the field's buzzword Deep Learning and the name of my blog Deep Python i.e. Deepython.com Convolutional Neural Networks are an extension of Artificial Neural Networks, which use a variation of multi-layer perceptrons and require minimal preprocessing of the data. Multi-layer perceptrons are mathematical expressions that map some set of input values to output values. As a whole, Convolutional Neural Networks usually have an input layer, several hidden layers, and an output layer. These layers can be convolutional, pooling, or fully connected as a traditional multi-layer perceptron network would be. As is standard, these networks employ backpropagation to calculate the error each neuron contributes to the network, through calculating the gradient of the loss function. The most commonly used loss function is the cross entropy loss function . Then, an optimization algorithm such as gradient descent is used to modify weights and biases to iteratively move toward the minimum of the loss function at some previously defined learning rate. Convolutional Neural Networks have been found to greatly improve classification accuracy for complex tasks such as image classification, facial recognition, natural language processing, drug discovery, and are even beating humans at complex games such as Go. In fact, competing against humans in video games such as Starcraft and Dota2 is an active area of research in deep learning, as it requires a high number of dimensions to represent a game at a given instant. So the deepness in Deep Learning is a term that typically refers to neural networks that employ many layers of neurons like multi-layer peceptrons or sigmoid neuron for feature extraction and learning. They take base level information such as the brightness of individual pixels in an image, and add layers that progressively accumulate information about edges, shapes, groups of shapes, and faces for example. Neural Networks employ these techniques to solve difficult and nebulous problems by breaking them down into a hierarchy of components that gradually increase in complexity. As mentioned previously, these networks are particularly useful in unsupervised learning , in which the representation of the data is learned from scratch by the network itself. This is important, as the vast majority of data being produced in the world is unlabeled, such as the sentiment of reddit comments, or audio does not have transcription available. Overall, this is an exciting area that I am looking forward to learning more about, and this is just a brief overview of the basics. Until next time, Clayton Blythe | Deep Python","tags":"Deep Learning","url":"deep-learning-101.html"},{"title":"Deep Archer","text":"Deep Archer: Style Transfer for a Hip Profile Picture This is a post about using an interesting technique that is coming out of deep learning, called style transfer, to make a profile picture for myself using the Archer cartoon animation style, to change the look of my profile picture for my company's internal slack channel. Neural Networks are getting pretty advanced, so much so that they can transfer the style of one image onto another. Naturally, I this would be a fun project for me to explore the area of deep learning in Python. Let's go!! This post will be discussion the most recent papers that have come out in the past couple years, called Image Style Transfer Using Convolutional Neural Networks and Perceptual Losses for Real-Time Style Transfer and Super-Resolution How about that for some light reading..heh So here are the following topics that are the main concepts allowing this type of deep neural network style transfer, and they will allow us to make new art! Key concepts for this post: 1. Artificial Neural Networks 2. Convolutional Recurrent Neural Networks (CNNs) 3. Deep Learning Until next time, Clayton Blythe | Deep Python","tags":"Deep Learning","url":"deep-archer.html"},{"title":"Introducing Deep Python","text":"Deep Python: A Christening Python: A large heavy-bodied nonvenomous constrictor snake occurring throughout the Old World tropics. ...Sorry to get your hopes up, but this won't be a discussion about snakes nor our reptilian overlords that run the U.S government. Rather, this is the first post of my new blog called Deep Python . I am writing this blog as a hobby, as I begin my own personal learning adventure and career in the area of neural networks, deep learning, and artificial intelligence. I plan to use this as an outreach avenue, but also as a knowledge repository for myself and others to use. Just so you know what's to come, the blog will cover a wider array of topics that contribute toward the projects that I take on, and I might even write about some miscellaneous topics as well. I imagine that I will cover relevant topics like Python , Pytorch , TensorFlow , Linux , Spark , Git , Vulpix and Docker ...Now which one of those was a pokemon? Joking aside, don't be surprised at the occasional excursion into economics, current news, and personal finance. Anyways, I think that is long enough for my first post. I'll keep it short and sweet, but I have quite a few ideas for posts to come! Feel free to send me an email at claytondblythe@gmail.com if you have ideas for projects, posts, or suggestions for improvement. Until next time, Clayton Blythe | Deep Python","tags":"General","url":"introducing-deep-python.html"}]}