<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>A Pelican Blog - Deep Learning</title><link href="/" rel="alternate"></link><link href="/feeds/deep-learning.atom.xml" rel="self"></link><id>/</id><updated>2017-10-02T13:10:00+00:00</updated><entry><title>Neural Selfie</title><link href="/neural-selfie.html" rel="alternate"></link><published>2017-10-02T13:10:00+00:00</published><updated>2017-10-02T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-10-02:/neural-selfie.html</id><summary type="html">&lt;p&gt;I recently have been trying to learn PyTorch, as it is becoming more popular for machine learning researchers because of its ability to represent complex neural network architectures in just a few lines of code. It also allows for dynamic definition of graphs, unlike its main competitor TensorFlow. This becomes …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently have been trying to learn PyTorch, as it is becoming more popular for machine learning researchers because of its ability to represent complex neural network architectures in just a few lines of code. It also allows for dynamic definition of graphs, unlike its main competitor TensorFlow. This becomes very useful for working with Recurrent Neural Networks for example. &lt;/p&gt;
&lt;p&gt;For this post, I implement the Neural Style Transfer algorithm in &lt;a href="https://arxiv.org/abs/1508.06576"&gt;this paper&lt;/a&gt; that takes a content image and a style image and returns a version of that content image with the appropriate "style". &lt;/p&gt;
&lt;p&gt;The main idea is that two distances are defined for the content and one for the style. The goal is to transform the image to minimize both the content distance with respect to the content image and vice versa for the style image. &lt;/p&gt;
&lt;p&gt;In the implementation described in the &lt;a href="http://pytorch.org/tutorials/advanced/neural_style_tutorial.html"&gt;PyTorch Documentation&lt;/a&gt; a pretrained VGG convolutional neural network is used as a base starting point. The content distance is defined as the sum of all squared differences between the feature maps at each Lth layer of the content and produced images, for every ith element of that layer's feature map.&lt;/p&gt;
&lt;p&gt;The style distance is more obscure, using a Gram produce of vectorized feature maps, representing the correlation between feature maps at some layer for both style and output images. The gradients for both distances/losses are calculated and summed together, and then backpropagation is done. &lt;/p&gt;
&lt;p&gt;For example, we can do style transfer of "Starry Night" onto a selfie of myself. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://deepython.com/images/starrynight.png"&gt;
&lt;img alt="Alt Test" src="https://deepython.com/images/headshot.png"&gt;&lt;/p&gt;
&lt;p&gt;And here is the result: 
&lt;img alt="Alt Test" src="https://deepython.com/images/starryn_cw0.6.png"&gt;&lt;/p&gt;
&lt;p&gt;I think that the results are pretty amazing to be honest, however it should be noted that I ran hundreds of different weight combinations for different images, and hand-picked the best results to post on here. I think it has produced some interesting pictures that I plan to use on for online profile pictures. &lt;/p&gt;
&lt;p&gt;Here are a couple more results. The first was created using a green spider-web looking image, and the second with the famous "Scream" painting. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://deepython.com/images/trial_19642857_3.8.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://deepython.com/images/trial_6957597_0.2.png"&gt;&lt;/p&gt;
&lt;p&gt;Overall, I had a blast working on this project. It was a great opportunity for me to experiment with neural networks and PyTorch. I'm looking forward to learning more! &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content></entry><entry><title>CS231n Lecture 5 Notes</title><link href="/cs231n-lecture-5-notes.html" rel="alternate"></link><published>2017-09-13T13:10:00+00:00</published><updated>2017-09-13T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-13:/cs231n-lecture-5-notes.html</id><summary type="html">&lt;p&gt;The purpose of this lecture was to introduce neural networks, and it extends beyond linear classification and describes how the "wiggle" (non-linearity) of neural networks are generated. The calculation of a score formula s=Wx is extended to add a clamping function like max(0, W1x) where an arbitrary number …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The purpose of this lecture was to introduce neural networks, and it extends beyond linear classification and describes how the "wiggle" (non-linearity) of neural networks are generated. The calculation of a score formula s=Wx is extended to add a clamping function like max(0, W1x) where an arbitrary number of weight matrices W1, W2 etc can be learned with stochastic gradient descent by calculating local gradients through backpropagation and the chain rule. &lt;/p&gt;
&lt;p&gt;These weight parameters and matrices are learned through the training process. The sizes of these intermediate hidden vectors are hyperparameters that can be determined through grid searching. The lecture then discusses the concept of a forward-propagating neuron, in which each neuron performs a dot product of the input and its weights, adds a bias, and applies the non-linearity (like the sigmoid activation function). &lt;/p&gt;
&lt;p&gt;A single neuron can also be thought of as a linear classifier, either a binary softmax classifier or a binary support vector machine classifier if a max-margin hinge loss is added to the output.&lt;/p&gt;
&lt;h3&gt;Activation Functions&lt;/h3&gt;
&lt;h4&gt;&lt;strong&gt;Sigmoid&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The sigmoid function has two major drawbacks. One is that the neuron's activation function saturates at 0 and 1, leading to a cradient at these regions that is almost zero. Therefore almost no signal will flow through the neuron to its weights. Therefore you must be careful when initializing weights. The other undesirable aspect is that sigmoid outputs are not zero centered. Neurons in later layers of the neural network will be receiving data that is not zero centered, and gradient
descent would be zig zagging. However, by using batches of data for updating the weights, this can be mitigated. &lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Tanh&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The tanh is usually preferred to the sigmoid nonlinearity, where the output is zero centered&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;ReLU&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The rectified linear unit computes the max(0,x) function and is thresholded at zero. The advantages are that it has been found to greatly accelerate stochastic gradient descent. The ReLU can be implemented by just thresholding a matrix of activations at zero. However, ReLU units can be fragile and die. If the learning rate is set too high, a large gradient flowing through a ReLU neuron can cause the weights to update in such a way that the neuron will never activate on a datapoint
again. &lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Leaky ReLU&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is an attempt to fix the dying ReLU problem, with mixed success.&lt;/p&gt;
&lt;p&gt;Usually the ReLU is chosen, while monitoring the fraction of dead units in a network. &lt;/p&gt;
&lt;h3&gt;Neural Network Architecture&lt;/h3&gt;
&lt;p&gt;Neural networks can be modeled as collections of neurons that are connected in a acyclic graph, where the outputs of some neurons become the inputs of other neurons. No cycles are allowed, and the neurons are organized into layers, commonly fully connected ones. The output layer is often the number of categories for the desired prediction, two for binary classifcation or ten for the ten categories in the CIFAR-10 dataset for example. They also usually do not have an activation
function, as the values are mean to be interpreted as scores for classification or some value for regression. The input layer is usually not counted, so logistic regression or support vector machines can be thought of as a single-layer neural network, where the inputs map directly to the outputs. Overall, these networks are interchangeably referred to as
&lt;em&gt;Artificial Neural Networks&lt;/em&gt; and &lt;em&gt;Multi-Layer Perceptrons&lt;/em&gt;, and besides being inspired by biological neurons, they don't have much in common. &lt;/p&gt;
&lt;p&gt;Two common metrics for describing neural network architecture are the size (number of neurons) or the number of parameters. Modern Convolutional Networks contain hundreds of millions of parameters and are often ten to twenty layers deep. &lt;/p&gt;
&lt;p&gt;This allows for nicely organized architectures, where each layer's weights and biases can be stored in matrixes, and the activations of all neurons in a particular layer can be calculated by using the dot product. A full forward pass of a three layer network is three matrix multiplications, with an activation function being used. All three weight matrices and all three bias matrices are then learnable parameters of the network. Entire batches of training data can be evaluated in
parallel then as well, by expanding the the dot product to use multiple input column vectors. The forward pass of a fully-connected layer uses one matrix multiplication followed with a bias offset and activation function. &lt;/p&gt;
&lt;p&gt;It can be mathematically shown that any continuous function can be modeled in this way with a neural network of at least one hidden layer. Neural networks work well because they can describe complicated functions in a compact and efficient manner, through the use of linear algebra, optimization through gradient descent, and hyperparameter tuning.&lt;/p&gt;
&lt;p&gt;Despite the fact that adding more layers allows for approximating higher dimension functions more accurately, it also leads to a greater chance of overfitting and lower generalization accuracy. Overall, the regularization strength parameter is the preferred way to control this overfitting. &lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Different activation functions were described, with ReLU being the most common choice&lt;/li&gt;
&lt;li&gt;Neural Networks with fully connected layers were described, with outputs from one layer mapping to the next layer&lt;/li&gt;
&lt;li&gt;This architecture enables efficient evaluation of neural networks through matrix multiplicaiton, stochastic gradient descent, and using an activation function.&lt;/li&gt;
&lt;li&gt;Neural networks are universal function approximaters, though can be prone to overfitting if proper precautions (some form of regularization) are not considered&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="cs231n"></category><category term="python"></category><category term="notes"></category><category term="neural networks"></category></entry><entry><title>CS231n Lecture 4 Notes</title><link href="/cs231n-lecture-4-notes.html" rel="alternate"></link><published>2017-09-03T13:10:00+00:00</published><updated>2017-09-03T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-03:/cs231n-lecture-4-notes.html</id><summary type="html">&lt;p&gt;The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through recursive application of the chain rule, that you might be familiar with from multivariable calculus. &lt;/p&gt;
&lt;p&gt;Most of this section can be understood by reviewing the concept of how local derivatives can be calculated through the chain rule by using the output at that point and nearby gradients. The name "backpropagation" refers to how the chain rule is applied recursively backwards (i.e. backpropagating) through the circuit and can be thought of as gates communicating to each other, telling each other whether they want their outputs to increase or decrease in the aim of making the final output value higher. &lt;/p&gt;
&lt;p&gt;So to reiterate, the &lt;em&gt;forward pass&lt;/em&gt; computes values from input to output, and the &lt;em&gt;backward pass&lt;/em&gt; starts at the end and recursively applies the chain rule to sequentially compute the gradients. As a result, the gradients can be thought of as flowing backwards through the circuit. &lt;/p&gt;
&lt;p&gt;The interesting behavior is that to understand and calculate backpropagation, you only need local characteristics of the circuit such as output value of the gate and the local gradient of the inputs of a node with respect to the output value of that node. &lt;/p&gt;
&lt;p&gt;The lecture then uses an example with the &lt;a href="https://en.wikipedia.org/wiki/Activation_function"&gt;sigmoid activation function&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Patterns in backward flow:
1. Add
2. Multiply
3. Maximum&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;add gate&lt;/em&gt; always takes the gradient on its output and distributes it equally to all of its inputs, regardless of what the values were during the forward pass. &lt;/p&gt;
&lt;p&gt;The &lt;em&gt;multiply gate&lt;/em&gt; has local gradients as input values, and this is multiplied on its output during the chain rule.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;max gate&lt;/em&gt; routes the gradient, distributing the gradient to exactly one of its inputs. &lt;/p&gt;
&lt;p&gt;Summary: This section provided intuition for what role gradients play in neural networks and how they relate to backpropagation. The section also how these gradients flow backwards through the "circuit", determining which parts components (weights and biases) should increase or decrease to force the final output higher. It also discussed the idea of &lt;em&gt;staged computation&lt;/em&gt; for implementing backpropagation in an iterative fashion. The idea is to break up your function into modules to derive local gradients and then chain them. The key is to decompose expressions into stages such that you can
differentiate each stage independently, working through the circuit one step at a time. &lt;/p&gt;
&lt;p&gt;The next section will start discussion neural networks and how backpropagation allows for efficiently computing the gradients of the connections with respect to a loss function. &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="cs231n"></category><category term="python"></category><category term="notes"></category><category term="neural networks"></category></entry><entry><title>CS231n Lecture 3 Notes</title><link href="/cs231n-lecture-3-notes.html" rel="alternate"></link><published>2017-08-29T13:10:00+00:00</published><updated>2017-08-29T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-29:/cs231n-lecture-3-notes.html</id><summary type="html">&lt;p&gt;I have recently been making my way through the Stanford Master's in Computer Science 231n course. This particular lecture
was about defining a loss function for how a simple Linear Classifier performs at classifying categories during training time,
and this metric in a sense quantifies how "unhappy" our scores are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have recently been making my way through the Stanford Master's in Computer Science 231n course. This particular lecture
was about defining a loss function for how a simple Linear Classifier performs at classifying categories during training time,
and this metric in a sense quantifies how "unhappy" our scores are across the training data.&lt;/p&gt;
&lt;p&gt;The task then is to find a way to efficiently find parameters (Weights and Biases) that minimize and optimize the loss function, useually via some optimization algorithm like Gradient Descent.&lt;/p&gt;
&lt;h3&gt;Loss Functions&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Multiclass SVM Loss&lt;/li&gt;
&lt;li&gt;Softmax Classifier (Cross-Entropy Loss / Multinomial Logistic Regression)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;em&gt;Multiclass SVM Loss&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The average across all the differences of the scores between the correct class and incorrect classes with a constant of one added. 1/N * Sigma { ((Incorrect class score  - Correct class score) + 1)} . Using a value of one here is
arbitrary and really just determines what magnitude the weights can be.&lt;/p&gt;
&lt;p&gt;Here when we initialize the weights, they are chosen to be small numbers, so in this case the initial value for the loss will be 2. Weight values can be multiplied in the same way, and they could be twice as large and achieve the same Loss (ignoring bias).&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Softmax Loss&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Softmax Loss is a different functional form for how loss is specified across scores. This assumes that the scores are unormalized log probabilities for each class. To get probabilities for each class,
we take the exponentiated scores for each element divided by the sum of all exponentiated elements. So here we want to maximize the log likelihood, or for a loss function we want to
minimize the negative log likelihood of the correct class. It turns out that maximizing this is more mathematically conducive than maximizing the negative probabilities themselves.
For the example of classifying a cat, if the normalized probability of a cat class is .13 then the loss would be -log(.13)= .89, and we are trying to maximize this, where zero is the minimum and there is no bounded maximum.&lt;/p&gt;
&lt;p&gt;When we initialize weights we typically choose them to be very small, so there should be an initial loss of -log( 1 / number of classes), as the initial scores would be zero, then unormalized probabilities of 1 for every class, then
the loss should be -log( 1 / # of classes ). As the model trains, the loss should move toward zero.&lt;/p&gt;
&lt;p&gt;Optimization occurs by finding the gradient of the loss function with respect to certain parameters, usually the weights for each class. In practice an analytic gradient is used, which is an exact, fast, but error-prone method.
You often then do a gradient check, where you compare the numerical gradient which is usually approximate, slow, but easy to write compared to your analytic gradient.&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Weight Regularization&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Weight regularization is a set of techniques to add objectives to the loss function, such that there exists a tradeoff between training error and generalization error. 
The most common form of regularization in neural networks is L2 regularization, also known as weight decay. This push$
Therefore regularization loss is a new component that contributes to the overall loss, and it is only a function of 
Including this weight regularization in the overall loss function that you are trying to minimize leads to weights that are diffuse, making sure that the network does not overfit certain regions of the image. This leads to better generalization performance at testing time.&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Stochastic Gradient Descent&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;This process is usually composed of two steps:
  1. Find the weights gradient by evaluating the gradient of the loss function with respect to the parameters of your training data, the weights. 
  2. Set new weights by multiplying step size (a.k.a. learning rate) by the gradient of the loss function with respect to weights, most importantly in the direction of the negative gradient. The gradient points in the direction of maximal increase, so the negative gradient will modify the parameters of the network closer to minimizing the loss function, or at least moving toward some local minimum.&lt;/p&gt;
&lt;p&gt;The learning rate/step size is an important hyperparameter for this.&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Mini-batch Gradient Descent&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Instead of using all training samples for each iteration (finding the gradient of the loss function corresponding to all your training data), you can use a small &lt;em&gt;batch&lt;/em&gt; comprised of a small subset of your training data. Then you can get a good approximation of the gradient and use smaller step sizes rather than using a full-batch size for each iteration or epoch.
Often this isn't a very significant hyperparameter to tune, but rather you choose this based on your GPU architecture and the constraints of your memory.
The key is finding the appropriate learning rate to converge over time across epochs (full cycles through your training data).&lt;/p&gt;
&lt;p&gt;The loss function can be thought of as an optimization problem in high-dimensional space, in which we are trying to reach the bottom of some high-dimensional valley. We start with some random initialization of weights and through iterative differentiation and adjustment we can reach the bottom. The next important concept to cover will be backprogation, essentially how to compute the gradient analytically by using the chain rule. &lt;/p&gt;
&lt;p&gt;The advancements recently (since roughly 2012) of using these techniques for neural networks are that you do not have to hand-craft features regarding your images, but rather you can train your entire network and the network automatically learns feature
without explicitly being programmed the structure of features or objects, like most rule-based recognition systems of the past were. Here the networks can be trained all the way back to the raw pixels, which make them very powerful and flexible at solving a wide array of problems in sound, image, and pattern recognition.&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="cs231n"></category><category term="notes"></category><category term="python"></category><category term="neural networks"></category></entry><entry><title>Single-Shot Detector Prototype</title><link href="/single-shot-detector-prototype.html" rel="alternate"></link><published>2017-08-29T13:10:00+00:00</published><updated>2017-08-29T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-29:/single-shot-detector-prototype.html</id><summary type="html">&lt;p&gt;I have wanted to experiment with multibox object detection and semantic segmentation in urban environments, so I started this very rough prototyping project for implementing SSD (Single-Shot Detector) in an urban environment, to detect things like pedestrians, bikes, cars, and buses. The SSD model is known for being fast at …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have wanted to experiment with multibox object detection and semantic segmentation in urban environments, so I started this very rough prototyping project for implementing SSD (Single-Shot Detector) in an urban environment, to detect things like pedestrians, bikes, cars, and buses. The SSD model is known for being fast at inference time and it performs object localization and classification in one pass. Also, I could readily find examples written in PyTorch on github &lt;a href="https://github.com/amdegroot/ssd.pytorch"&gt;here&lt;/a&gt;. I used this repository heavily, and
started my own project to run an SSD network on a &lt;a href="https://www.youtube.com/watch?v=Kk26RfjhFz0"&gt;4k video&lt;/a&gt; of someone walking through Times Square in New York. I figured that it would be a good opportunity to experiment with these types of networks in a real-world environment. &lt;/p&gt;
&lt;p&gt;Here is an example of an image in Times Square to classify. You can see there are pictures of various people walking around, including a couple people in Elmo costumes! &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="http://deepython.com/images/elmo.png"&gt;&lt;/p&gt;
&lt;p&gt;Here is the downsampled images preprocessed with subracted mean for SSD. This type of preprocessing is typical for these types of image processing tasks.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="http://deepython.com/images/condensed_rgb_elmo.png"&gt;&lt;/p&gt;
&lt;p&gt;Here is the final result with bounding boxes and entity classification! I think it does a pretty darn good job at classification, even on the people in Elmo costumes.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="http://deepython.com/images/elmo_boxed.png"&gt;&lt;/p&gt;
&lt;p&gt;I think this was a fun prototype for me to get my feet wet a little bit. It is pretty slow even on GPU, as I am using a pretty verbose PyTorch script and using the PIL image library which adds a fair amount of overhead. &lt;/p&gt;
&lt;p&gt;Next, I plan on writing a python script to pipe frames from ffmpeg to create classification bounding boxes. I also plan on experimenting with more compact model architectures like SqueezeNet. &lt;a href="https://github.com/claytonblythe/citywatch"&gt;Here&lt;/a&gt; is my Github repo if you want to take a look. &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content></entry><entry><title>Deep Learning 101: A Brief Introduction</title><link href="/deep-learning-101-a-brief-introduction.html" rel="alternate"></link><published>2017-08-18T22:19:00+00:00</published><updated>2017-08-18T22:19:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-18:/deep-learning-101-a-brief-introduction.html</id><summary type="html">&lt;p&gt;So you want to learn about Deep Learning huh?&lt;/p&gt;
&lt;p&gt;Well I'm not sure I'm quite qualified yet, as I just started learning about this myself. But the best way to learn something is to try to teach it to other people, so here I am. I hope you find this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So you want to learn about Deep Learning huh?&lt;/p&gt;
&lt;p&gt;Well I'm not sure I'm quite qualified yet, as I just started learning about this myself. But the best way to learn something is to try to teach it to other people, so here I am. I hope you find this post and blog useful.&lt;/p&gt;
&lt;p&gt;To begin our understanding of this field, we need to introduce the topic of machine learning. &lt;a href="https://www.wikiwand.com/en/Machine_learning"&gt;Machine Learning&lt;/a&gt; is the ability of a computer to aquire knowledge and make predictions through extracting latent patterns and information from data. Machine Learning can almost be thought of as a form of applied statistics, in which computers statistically estimate some function. Within machine learning, problems can usually be broken down into &lt;a href="https://www.wikiwand.com/en/Supervised_learning"&gt;supervised learning&lt;/a&gt; and &lt;a href="https://www.wikiwand.com/en/Unsupervised_learning"&gt;unsupervised learning&lt;/a&gt;. The former infers or approximates some function from labeled training data, where the function represents a relationship between input variables (often called features) and a labeled or known output value. In unsupervised learning, the task is to describe the hidden structure and properties of input data without explicitly being given labeled training data. Within machine learning there is a subdomain called &lt;a href="https://www.wikiwand.com/en/Deep_learning"&gt;Deep Learning&lt;/a&gt;, and this area will be the primary focus of this blog, &lt;a href="https://deepython.com"&gt;&lt;em&gt;Deep Python&lt;/em&gt;&lt;/a&gt; @ &lt;a href="https://deepython.com"&gt;&lt;em&gt;deepython.com&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A couple fundamental concepts in deep learning are Artificial Neural Networks and Convolutional Neural Networks.&lt;/p&gt;
&lt;h2&gt;Key concepts:&lt;/h2&gt;
&lt;h3&gt;1. Artificial Neural Networks&lt;/h3&gt;
&lt;h3&gt;2. Convolutional Recurrent Neural Networks (CNNs)&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.wikiwand.com/en/Artificial_neural_network"&gt;Artificial Neural Networks&lt;/a&gt; are systems created by modern computing systems created to complete complex tasks such as image and sound recognition. They were inspired by traditional biological networks, which are adept at completing complex tasks like recognizing faces, understanding audible speech, or translating one written language into another. The important thing is that these tasks are extremely difficult to formalize into traditional rule-based systems, and hence these problems have seen large progress through the development of neural networks.  &lt;/p&gt;
&lt;p&gt;This is the most promising and conceptually difficult area of machine learning, as it requires employing linear algebra along with modern GPU architecture to create a complex network of connected neurons which allow computers to learn complex patterns from experiences, and to solve problems through breaking tasks down into simpler, more manageable components. This is done by stacking several "layers" of mathematical operations and transformations on top of one another, hence the field's buzzword
&lt;em&gt;Deep Learning&lt;/em&gt; and the name of my blog &lt;em&gt;Deep Python&lt;/em&gt; @ &lt;a href="http://deepython.com"&gt;&lt;em&gt;deepython.com&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.wikiwand.com/en/Convolutional_neural_network"&gt;Convolutional Neural Networks&lt;/a&gt; then are an extension of Artificial Neural Networks, which use a variation of &lt;a href="https://www.wikiwand.com/en/Multilayer_perceptron"&gt;multi-layer perceptrons&lt;/a&gt; and require minimal preprocessing of the data. &lt;a href="https://www.wikiwand.com/en/Multilayer_perceptron"&gt;Multi-layer perceptrons&lt;/a&gt; are mathematical expressions that map some set of input values to output values. As a whole, Convolutional Neural Networks usually have an input layer, several hidden layers, and an output layer. These layers can be convolutional, pooling, or fully connected as a traditional multi-layer perceptron network would be. As is standard, these networks employ &lt;a href="https://www.wikiwand.com/en/Backpropagation"&gt;backpropagation&lt;/a&gt; to calculate the error each neuron contributes to the network's discriminatory ability, through calculating the &lt;a href="https://www.wikiwand.com/en/Gradient"&gt;gradient&lt;/a&gt; of the loss function. A gradient can be though of as a mathematical operation that finds the direction of maximal increase (consequently the opposite direction is  used for minimization). Throughout these layers, there are parameters called biases and weights that represent the underlying mathematical operations of matrix multiplication. Then, these weights and biases are used to calculate some set of final values, often scores for different classes. These cores are then mapped to a loss function that represent's error in the network's discriminatory ability. &lt;/p&gt;
&lt;p&gt;The most commonly used loss function is the &lt;a href="https://www.wikiwand.com/en/Loss_functions_for_classification#/Cross_entropy_loss"&gt;cross entropy loss function&lt;/a&gt;. Then, an optimization algorithm such as &lt;a href="https://www.wikiwand.com/en/Gradient_descent"&gt;gradient descent&lt;/a&gt; is used to modify weights and biases to iteratively move toward the minimum of the loss function at some previously defined learning rate.&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;Convolutional Neural Networks&lt;/em&gt; (CNN's)&lt;/h2&gt;
&lt;p&gt;Convolutional Neural Networks have been found to greatly improve classification accuracy for &lt;a href="https://www.wikiwand.com/en/Convolutional_neural_network#/Applications"&gt;complex tasks&lt;/a&gt; such as image classification, facial recognition, natural language processing, drug discovery, and are even beating humans at complex games such as Go. In fact, competing against humans in video games such as Starcraft and Dota2 is an active area of research in deep learning, as it requires a high number of dimensions to represent a game at a given instant.  &lt;/p&gt;
&lt;p&gt;So the &lt;em&gt;deepness&lt;/em&gt; in &lt;a href="https://www.wikiwand.com/en/Deep_learning"&gt;&lt;em&gt;Deep Learning&lt;/em&gt;&lt;/a&gt;  is a term that typically refers to neural networks that employ many layers of neurons like multi-layer peceptrons or &lt;a href="https://www.wikiwand.com/en/Sigmoid_function"&gt;sigmoid neurons&lt;/a&gt; for feature extraction and learning. They take raw, base level information such as the brightness of individual pixels in an image, and add layers that progressively accumulate more complex information like edges, shapes, groups of shapes, and faces. Neural Networks employ these techniques to solve difficult and nebulous problems by breaking them down into a hierarchy of components that gradually increase in complexity. As mentioned previously, these networks are particularly useful in  &lt;a href="https://www.wikiwand.com/en/Unsupervised_learning"&gt;unsupervised learning&lt;/a&gt;, in which the representation of the data is learned from scratch by the network itself. This is an important emerging area of research, as the vast majority of data being produced in the world is unlabeled, such as the sentiment of reddit comments, or audio that does not have transcription available.&lt;/p&gt;
&lt;p&gt;Overall, this is an exciting area that I am looking forward to learning more about, and this is just a high-level overview of the basics.&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="python"></category><category term="neural networks"></category><category term="intro"></category></entry></feed>