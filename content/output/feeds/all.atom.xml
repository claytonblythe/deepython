<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>A Pelican Blog</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2017-10-26T13:10:00+00:00</updated><entry><title>Asynchronously Scraping deepython.com</title><link href="/asynchronously-scraping-deepythoncom.html" rel="alternate"></link><published>2017-10-26T13:10:00+00:00</published><updated>2017-10-26T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-10-26:/asynchronously-scraping-deepythoncom.html</id><summary type="html">&lt;p&gt;I wanted to learn more about how to do asynchronous web scraping in python3 using the asyncio and aiohttp libraries. Let's assume I have a large number of urls that I want to scrape, and they are all contained in a list, say 10,000 elements long. In synchronous scraping …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I wanted to learn more about how to do asynchronous web scraping in python3 using the asyncio and aiohttp libraries. Let's assume I have a large number of urls that I want to scrape, and they are all contained in a list, say 10,000 elements long. In synchronous scraping, the client running the python script will send a requst to url of the server hosting the html content, wait for a response containing this html content, proceed to the next url, send another request and so on. &lt;/p&gt;
&lt;p&gt;In contrast, asynchronous scraping with the asyncio and aiohttp libraries will create a queue of scraping tasks, and while a particular task is waiting for the web content to arrive from the server, it will go ahead and request content from other web pages while waiting. This allows for making requests and receiving content concurrently instead of in a sequential fashion, enabling a large number of web requests to be completed in a short time. &lt;/p&gt;
&lt;p&gt;In &lt;a href="https://github.com/claytonblythe/async_examples/blob/master/notebooks/deepython_requests.ipynb"&gt;this github repo&lt;/a&gt; I show that scraping the html content from the home page of my website &lt;a href="http://deepython.com"&gt;deepython.com&lt;/a&gt; (served from my raspberry pi) 10,000 times only takes about twenty seconds, compared to several minutes in the sequential example. &lt;/p&gt;
&lt;p&gt;This difference would only be exacerbated if you have urls and web servers that take a wide range of time to respond. So here this can give speedups for web scraping of 10x or 100x+ if you are lucky! I think that there are some interesting applications for this, doing large scale scraping of websites. &lt;/p&gt;
&lt;p&gt;Next it is useful to use some type of proxies and random user agents, to make it more difficult for websites to tell that you are sending an unnatural number of requests. &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content></entry><entry><title>Neural Selfie</title><link href="/neural-selfie.html" rel="alternate"></link><published>2017-10-02T13:10:00+00:00</published><updated>2017-10-02T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-10-02:/neural-selfie.html</id><summary type="html">&lt;p&gt;I recently have been trying to learn PyTorch, as it is becoming more popular for machine learning researchers because of its ability to represent complex neural network architectures in just a few lines of code. It also allows for dynamic definition of graphs, unlike its main competitor TensorFlow. This becomes …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently have been trying to learn PyTorch, as it is becoming more popular for machine learning researchers because of its ability to represent complex neural network architectures in just a few lines of code. It also allows for dynamic definition of graphs, unlike its main competitor TensorFlow. This becomes very useful for working with Recurrent Neural Networks for example. &lt;/p&gt;
&lt;p&gt;For this post, I implement the Neural Style Transfer algorithm in &lt;a href="https://arxiv.org/abs/1508.06576"&gt;this paper&lt;/a&gt; that takes a content image and a style image and returns a version of that content image with the appropriate "style". &lt;/p&gt;
&lt;p&gt;The main idea is that two distances are defined for the content and one for the style. The goal is to transform the image to minimize both the content distance with respect to the content image and vice versa for the style image. &lt;/p&gt;
&lt;p&gt;In the implementation described in the &lt;a href="http://pytorch.org/tutorials/advanced/neural_style_tutorial.html"&gt;PyTorch Documentation&lt;/a&gt; a pretrained VGG convolutional neural network is used as a base starting point. The content distance is defined as the sum of all squared differences between the feature maps at each Lth layer of the content and produced images, for every ith element of that layer's feature map.&lt;/p&gt;
&lt;p&gt;The style distance is more obscure, using a Gram produce of vectorized feature maps, representing the correlation between feature maps at some layer for both style and output images. The gradients for both distances/losses are calculated and summed together, and then backpropagation is done. &lt;/p&gt;
&lt;p&gt;For example, we can do style transfer of "Starry Night" onto a selfie of myself. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://deepython.com/images/starrynight.png"&gt;
&lt;img alt="Alt Test" src="https://deepython.com/images/headshot.png"&gt;&lt;/p&gt;
&lt;p&gt;And here is the result: 
&lt;img alt="Alt Test" src="https://deepython.com/images/starryn_cw0.6.png"&gt;&lt;/p&gt;
&lt;p&gt;I think that the results are pretty amazing to be honest, however it should be noted that I ran hundreds of different weight combinations for different images, and hand-picked the best results to post on here. I think it has produced some interesting pictures that I plan to use on for online profile pictures. &lt;/p&gt;
&lt;p&gt;Here are a couple more results. The first was created using a green spider-web looking image, and the second with the famous "Scream" painting. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://deepython.com/images/trial_19642857_3.8.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://deepython.com/images/trial_6957597_0.2.png"&gt;&lt;/p&gt;
&lt;p&gt;Overall, I had a blast working on this project. It was a great opportunity for me to experiment with neural networks and PyTorch. I'm looking forward to learning more! &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content></entry><entry><title>Network-wide Advertisement Blocking</title><link href="/network-wide-advertisement-blocking.html" rel="alternate"></link><published>2017-09-16T13:10:00+00:00</published><updated>2017-09-16T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-16:/network-wide-advertisement-blocking.html</id><summary type="html">&lt;p&gt;Recently, I setup my own home wifi network with Comcast.. &lt;em&gt;shudder&lt;/em&gt; However, it initially hasn't been that bad despite their lackluster reputation. I consistently get 75+ Mbps for my plan that costs $35.00 per month, a decent deal for a basic necessity of mine, wireless internet. &lt;/p&gt;
&lt;p&gt;I am a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently, I setup my own home wifi network with Comcast.. &lt;em&gt;shudder&lt;/em&gt; However, it initially hasn't been that bad despite their lackluster reputation. I consistently get 75+ Mbps for my plan that costs $35.00 per month, a decent deal for a basic necessity of mine, wireless internet. &lt;/p&gt;
&lt;p&gt;I am a person who has little patience for online advertising. Luckily, I saw this interesting project online about how you can use a rapsberry pi as a DNS server. A DNS server translates human-memorable domain names and hostnames into their corresponding IP addresses. The pi-hole doesn't sit in between your connected devices and the internet, but rather it is a DNS server that blacklists certain domain names, typically ones that host content. As a result, it doesn't allow any content to be retrieved if that hostname is contained within a
certain database of domain names. So, the router goes to the DNS server and says "hey I'm looking for this domain name, what's the IP address?" &lt;/p&gt;
&lt;p&gt;This allows all of the devices on your wireless network to enjoy advertisement-free internet browsing! Here are the steps that I took to get it set up. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the SD Formatter tool software from SanDisk&lt;/li&gt;
&lt;li&gt;Plug in a 8gb+ microSD card into a computer (you may have to use an adapter to SD depending on your computer) &lt;/li&gt;
&lt;li&gt;Using SD Formatter tool, select and overwrite the SD card to default settings, then quick format the card&lt;/li&gt;
&lt;li&gt;Download the latest version of NOOBS (New Out Of Box Software) from the &lt;a href="https://www.raspberrypi.org/downloads/noobs/"&gt;Raspberry Pi Foundation's website&lt;/a&gt;. Unzip the file. &lt;/li&gt;
&lt;li&gt;Copy the contents of the zip directory to the microSD card that you just formatted. &lt;/li&gt;
&lt;li&gt;Safely eject the SD card adapter&lt;/li&gt;
&lt;li&gt;Plug in the microSD card into the bottom of the raspberry pi, facing up&lt;/li&gt;
&lt;li&gt;Plug the power cord into raspberry pi, hook up to monitor and keyboard&lt;/li&gt;
&lt;li&gt;Select Raspbian OS (Based on Debian), hit the "i" key, wait for the OS to be installed&lt;/li&gt;
&lt;li&gt;Connect to wifi, then open terminal and copy and paste: curl -sSL https://install.pi-hole.net | bash &lt;/li&gt;
&lt;li&gt;Select the appropriate wireless/ethernet connection in setup &lt;/li&gt;
&lt;li&gt;Reserve static IP adress for raspberry pi&lt;/li&gt;
&lt;li&gt;Make sure to modify your router's network settings to use the static IP of the raspberry pi as a static DNS server &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content></entry><entry><title>CS231n Lecture 5 Notes</title><link href="/cs231n-lecture-5-notes.html" rel="alternate"></link><published>2017-09-13T13:10:00+00:00</published><updated>2017-09-13T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-13:/cs231n-lecture-5-notes.html</id><summary type="html">&lt;p&gt;The purpose of this lecture was to introduce neural networks, and it extends beyond linear classification and describes how the "wiggle" (non-linearity) of neural networks are generated. The calculation of a score formula s=Wx is extended to add a clamping function like max(0, W1x) where an arbitrary number …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The purpose of this lecture was to introduce neural networks, and it extends beyond linear classification and describes how the "wiggle" (non-linearity) of neural networks are generated. The calculation of a score formula s=Wx is extended to add a clamping function like max(0, W1x) where an arbitrary number of weight matrices W1, W2 etc can be learned with stochastic gradient descent by calculating local gradients through backpropagation and the chain rule. &lt;/p&gt;
&lt;p&gt;These weight parameters and matrices are learned through the training process. The sizes of these intermediate hidden vectors are hyperparameters that can be determined through grid searching. The lecture then discusses the concept of a forward-propagating neuron, in which each neuron performs a dot product of the input and its weights, adds a bias, and applies the non-linearity (like the sigmoid activation function). &lt;/p&gt;
&lt;p&gt;A single neuron can also be thought of as a linear classifier, either a binary softmax classifier or a binary support vector machine classifier if a max-margin hinge loss is added to the output.&lt;/p&gt;
&lt;h3&gt;Activation Functions&lt;/h3&gt;
&lt;h4&gt;&lt;strong&gt;Sigmoid&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The sigmoid function has two major drawbacks. One is that the neuron's activation function saturates at 0 and 1, leading to a cradient at these regions that is almost zero. Therefore almost no signal will flow through the neuron to its weights. Therefore you must be careful when initializing weights. The other undesirable aspect is that sigmoid outputs are not zero centered. Neurons in later layers of the neural network will be receiving data that is not zero centered, and gradient
descent would be zig zagging. However, by using batches of data for updating the weights, this can be mitigated. &lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Tanh&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The tanh is usually preferred to the sigmoid nonlinearity, where the output is zero centered&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;ReLU&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The rectified linear unit computes the max(0,x) function and is thresholded at zero. The advantages are that it has been found to greatly accelerate stochastic gradient descent. The ReLU can be implemented by just thresholding a matrix of activations at zero. However, ReLU units can be fragile and die. If the learning rate is set too high, a large gradient flowing through a ReLU neuron can cause the weights to update in such a way that the neuron will never activate on a datapoint
again. &lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;Leaky ReLU&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is an attempt to fix the dying ReLU problem, with mixed success.&lt;/p&gt;
&lt;p&gt;Usually the ReLU is chosen, while monitoring the fraction of dead units in a network. &lt;/p&gt;
&lt;h3&gt;Neural Network Architecture&lt;/h3&gt;
&lt;p&gt;Neural networks can be modeled as collections of neurons that are connected in a acyclic graph, where the outputs of some neurons become the inputs of other neurons. No cycles are allowed, and the neurons are organized into layers, commonly fully connected ones. The output layer is often the number of categories for the desired prediction, two for binary classifcation or ten for the ten categories in the CIFAR-10 dataset for example. They also usually do not have an activation
function, as the values are mean to be interpreted as scores for classification or some value for regression. The input layer is usually not counted, so logistic regression or support vector machines can be thought of as a single-layer neural network, where the inputs map directly to the outputs. Overall, these networks are interchangeably referred to as
&lt;em&gt;Artificial Neural Networks&lt;/em&gt; and &lt;em&gt;Multi-Layer Perceptrons&lt;/em&gt;, and besides being inspired by biological neurons, they don't have much in common. &lt;/p&gt;
&lt;p&gt;Two common metrics for describing neural network architecture are the size (number of neurons) or the number of parameters. Modern Convolutional Networks contain hundreds of millions of parameters and are often ten to twenty layers deep. &lt;/p&gt;
&lt;p&gt;This allows for nicely organized architectures, where each layer's weights and biases can be stored in matrixes, and the activations of all neurons in a particular layer can be calculated by using the dot product. A full forward pass of a three layer network is three matrix multiplications, with an activation function being used. All three weight matrices and all three bias matrices are then learnable parameters of the network. Entire batches of training data can be evaluated in
parallel then as well, by expanding the the dot product to use multiple input column vectors. The forward pass of a fully-connected layer uses one matrix multiplication followed with a bias offset and activation function. &lt;/p&gt;
&lt;p&gt;It can be mathematically shown that any continuous function can be modeled in this way with a neural network of at least one hidden layer. Neural networks work well because they can describe complicated functions in a compact and efficient manner, through the use of linear algebra, optimization through gradient descent, and hyperparameter tuning.&lt;/p&gt;
&lt;p&gt;Despite the fact that adding more layers allows for approximating higher dimension functions more accurately, it also leads to a greater chance of overfitting and lower generalization accuracy. Overall, the regularization strength parameter is the preferred way to control this overfitting. &lt;/p&gt;
&lt;h3&gt;Summary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Different activation functions were described, with ReLU being the most common choice&lt;/li&gt;
&lt;li&gt;Neural Networks with fully connected layers were described, with outputs from one layer mapping to the next layer&lt;/li&gt;
&lt;li&gt;This architecture enables efficient evaluation of neural networks through matrix multiplicaiton, stochastic gradient descent, and using an activation function.&lt;/li&gt;
&lt;li&gt;Neural networks are universal function approximaters, though can be prone to overfitting if proper precautions (some form of regularization) are not considered&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="cs231n"></category><category term="python"></category><category term="notes"></category><category term="neural networks"></category></entry><entry><title>Blogging with Vim and Pelican</title><link href="/blogging-with-vim-and-pelican.html" rel="alternate"></link><published>2017-09-09T13:10:00+00:00</published><updated>2017-09-09T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-09:/blogging-with-vim-and-pelican.html</id><summary type="html">&lt;p&gt;I have started to learn vim, and it has been a little painful to be honest. However, I have found it to be pretty liberating in that I barely need to use a mouse to do work on my laptop, especially for things like manipulating files, writing code, and even …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have started to learn vim, and it has been a little painful to be honest. However, I have found it to be pretty liberating in that I barely need to use a mouse to do work on my laptop, especially for things like manipulating files, writing code, and even editing/building my blog. &lt;/p&gt;
&lt;p&gt;I am slowly learning the tricks to quickly and efficiently navigate file structures, make changes to files, and even run normal bash commands as well. It was quit intimidating at first, but I am already finding it rewarding. Now, I have even written some custom commands and scripts to integrate my blog editing and deployment process that uses Pelican, a python utility for building sites and converting markdown text files to HTML. &lt;/p&gt;
&lt;p&gt;I think that it is important to be able to work as quickly and efficiently as possible, and not be hampered by menial things like taking time to open files, make changes, save them, and then see how the changes impact what you are trying to build or accomplish. The goal here is to make sure that my fingers and ability to navigate file structures aren't the limiting factors for my productivity, but rather the speed at which I can think and come up with solutions or content. &lt;/p&gt;
&lt;p&gt;For my blog, my workflow is as follows: I type "serve" in the command line which is a bash alias for changing to the directory of my blog, running a python/pelican development server which serves a local host replica of my blog. The blog is automatically opened in google chrome at http://localhost.com:8000 for me to browse and critique, as this 8000 port is the default for pelican. In an iterm2 terminal, I launch vim with the command "v", hit the leader key "," and shortly after "f" to open a small file browser plugin, which shows at the bottom most recently used files. There I can quickly move to different posts I had been working
on and use standard vim commands. In normal mode I type the leader key ',' and then shortly after I type 'z'. This allows me to perform edits in "focus mode", a minimalistic mode for the vim text editor that I find quite useful and aesthetically pleasing. This focus mode functionality comes from a vim plugin that comes with a vimrc repository that I will link at the bottom.&lt;/p&gt;
&lt;p&gt;One important customization I added to vim was to make the Caps Lock serve as an escape key, so I can easily revert back to normal mode without having to reach for the escape key, which can take a lot of time if you make hundreds of small edits.&lt;/p&gt;
&lt;p&gt;So I begin making changes, and then I write the buffer of the file onto disk with the ":w" vim command, which is connected to an autocmd hook in vim within ~/vim_runtime/my_configs.vim. This configuration calls the google chrome command line utility chrome-cli. Chrome-cli waits a little under a second for Pelican to build the static html pages, and then refreshes any tabs I have open that contain the title
of my blog,"deepython.com", in the description of the tab. &lt;/p&gt;
&lt;p&gt;Here is the specific autocmd added to ~/.vim_runtime/my_configs.vim file: &lt;/p&gt;
&lt;p&gt;autocmd BufWritePost *.md :!sleep .69 &amp;amp;&amp;amp; /Users/claytonblythe/github/version_control/scripts/reloadDeepython.sh&lt;/p&gt;
&lt;p&gt;The script reloadDeepython.sh contains the following: &lt;/p&gt;
&lt;p&gt;chrome-cli list tabs | grep deepython.com | cut -c 2-4 | while read -r line; do chrome-cli reload -t "$line"; done&lt;/p&gt;
&lt;p&gt;This assumes you have chrome-cli installed, which can be installed with "pip install chrome-cli"&lt;/p&gt;
&lt;p&gt;Using this configuration, I can get almost instant feed back about the aesthetics and content of my posts without even having to exit vim! &lt;/p&gt;
&lt;p&gt;It has been a pretty valuable way for me to learn about vim, python, and bash scripting, not to mention it is saving me a lot of time as well. &lt;/p&gt;
&lt;p&gt;Here is a photo of what my development environment looks like. Pretty slick huh? &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://deepython.com/images/blogSetup.png"&gt; &lt;/p&gt;
&lt;p&gt;Here are some other links used in this post: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/amix/vimrc"&gt;vimrc&lt;/a&gt; github repo&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/claytonblythe/version_control/blob/master/scripts/reloadDeepython.sh"&gt;chrome-cli&lt;/a&gt; script&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/prasmussen/chrome-cli"&gt;chrome-cli&lt;/a&gt; github repo&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I hope that you find this useful. &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="vim"></category></entry><entry><title>Manchester United Game Reminders with Python and Raspberry Pi</title><link href="/manchester-united-game-reminders-with-python-and-raspberry-pi.html" rel="alternate"></link><published>2017-09-09T13:10:00+00:00</published><updated>2017-09-09T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-09:/manchester-united-game-reminders-with-python-and-raspberry-pi.html</id><summary type="html">&lt;p&gt;Suprisingly, I have found that I have a lot more free time now in the real world working than I did during undergraduate study, but that might be because I was doing things like research programs and internships on top of taking seventeen credits a semester. However, now that I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Suprisingly, I have found that I have a lot more free time now in the real world working than I did during undergraduate study, but that might be because I was doing things like research programs and internships on top of taking seventeen credits a semester. However, now that I have this all this free time, I have started to follow sports more, specifically the English Premier League and NCAA Football. &lt;/p&gt;
&lt;p&gt;My favorite team in the English Premier League is Manchester United, however I couldn't be bothered to periodically check online, find their schedule, and determine when they play next. Additionally, I thought this would be a good opportunity for me to learn more about web scraping and python. So I built a simple web
scraping script to periodically parse Manchester United's upcoming schedule and text it to my iphone every couple of days. &lt;/p&gt;
&lt;p&gt;I have a python script called redDevilNotify.py running every two days on my Raspberry Pi which uses a Raspian Linux Distribution as the operating system. The Raspberry Pi is running 24/7 in my apartment, but it is very efficient and doesn't use much energy. 
The script uses the beautifulsoup python library to scrape the html of Manchester United's website for upcoming games, parses the html, converts the UTC dates to EST, and then it uses the Twilio API to text a reminder SMS to my iphone. &lt;/p&gt;
&lt;p&gt;The following crontab scheduling command is used to run the script, and you can edit this with the bash command bash:::crontab -e&lt;/p&gt;
&lt;p&gt;0 9 */2 * * /usr/bin/python3 /path/to/redDevilNotify.py &lt;/p&gt;
&lt;p&gt;This means that the script will run on the zeroth minute of the ninth hour every two days for every week and month of the year. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/claytonblythe/RedDevilNotify"&gt;Github Repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="raspberry pi"></category><category term="python"></category><category term="web scraping"></category><category term="soccer"></category></entry><entry><title>Regex to the Rescue</title><link href="/regex-to-the-rescue.html" rel="alternate"></link><published>2017-09-08T15:10:00+00:00</published><updated>2017-09-08T15:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-08:/regex-to-the-rescue.html</id><summary type="html">&lt;p&gt;For a project at work, I had to parse archaic mainframe flat files produced with Job Control Language (JCL) and COBOL, popular programming languages from decades ago. The difficulty is that for a given record or observation, there was no set way of distinguishing different fields, with no delimiters present …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For a project at work, I had to parse archaic mainframe flat files produced with Job Control Language (JCL) and COBOL, popular programming languages from decades ago. The difficulty is that for a given record or observation, there was no set way of distinguishing different fields, with no delimiters present. The bytes were squished up next to each other, with a specific record structure determined by various COBOL Copy Books is what they are called. &lt;/p&gt;
&lt;p&gt;So the task was to generate a relational data structure out of these variable length records, and within each record there are various segments, each with different fields of different lengths in bytes. As you can see, this quickly got complicated. &lt;/p&gt;
&lt;p&gt;However we can bring regular expressions to the rescue!&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="https://imgs.xkcd.com/comics/regular_expressions.png"&gt; &lt;/p&gt;
&lt;p&gt;(Source: https://imgs.xkcd.com/comics/regular_expressions.png)&lt;/p&gt;
&lt;p&gt;So I ended up looking for strings of text that start with a certain length of bytes for a key, followed by one of various segment indicators. Then I can use simple string splicing in Python with the shema specified by each segment's COBOL Copy Book to get the individual fields. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/claytonblythe/cobolRegex"&gt;Github Repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="cobol"></category><category term="regex"></category><category term="python"></category></entry><entry><title>CS231n Lecture 4 Notes</title><link href="/cs231n-lecture-4-notes.html" rel="alternate"></link><published>2017-09-03T13:10:00+00:00</published><updated>2017-09-03T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-03:/cs231n-lecture-4-notes.html</id><summary type="html">&lt;p&gt;The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through recursive application of the chain rule, that you might be familiar with from multivariable calculus. &lt;/p&gt;
&lt;p&gt;Most of this section can be understood by reviewing the concept of how local derivatives can be calculated through the chain rule by using the output at that point and nearby gradients. The name "backpropagation" refers to how the chain rule is applied recursively backwards (i.e. backpropagating) through the circuit and can be thought of as gates communicating to each other, telling each other whether they want their outputs to increase or decrease in the aim of making the final output value higher. &lt;/p&gt;
&lt;p&gt;So to reiterate, the &lt;em&gt;forward pass&lt;/em&gt; computes values from input to output, and the &lt;em&gt;backward pass&lt;/em&gt; starts at the end and recursively applies the chain rule to sequentially compute the gradients. As a result, the gradients can be thought of as flowing backwards through the circuit. &lt;/p&gt;
&lt;p&gt;The interesting behavior is that to understand and calculate backpropagation, you only need local characteristics of the circuit such as output value of the gate and the local gradient of the inputs of a node with respect to the output value of that node. &lt;/p&gt;
&lt;p&gt;The lecture then uses an example with the &lt;a href="https://en.wikipedia.org/wiki/Activation_function"&gt;sigmoid activation function&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Patterns in backward flow:
1. Add
2. Multiply
3. Maximum&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;add gate&lt;/em&gt; always takes the gradient on its output and distributes it equally to all of its inputs, regardless of what the values were during the forward pass. &lt;/p&gt;
&lt;p&gt;The &lt;em&gt;multiply gate&lt;/em&gt; has local gradients as input values, and this is multiplied on its output during the chain rule.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;max gate&lt;/em&gt; routes the gradient, distributing the gradient to exactly one of its inputs. &lt;/p&gt;
&lt;p&gt;Summary: This section provided intuition for what role gradients play in neural networks and how they relate to backpropagation. The section also how these gradients flow backwards through the "circuit", determining which parts components (weights and biases) should increase or decrease to force the final output higher. It also discussed the idea of &lt;em&gt;staged computation&lt;/em&gt; for implementing backpropagation in an iterative fashion. The idea is to break up your function into modules to derive local gradients and then chain them. The key is to decompose expressions into stages such that you can
differentiate each stage independently, working through the circuit one step at a time. &lt;/p&gt;
&lt;p&gt;The next section will start discussion neural networks and how backpropagation allows for efficiently computing the gradients of the connections with respect to a loss function. &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="cs231n"></category><category term="python"></category><category term="notes"></category><category term="neural networks"></category></entry><entry><title>My Git Workflow</title><link href="/my-git-workflow.html" rel="alternate"></link><published>2017-09-02T13:10:00+00:00</published><updated>2017-09-02T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-09-02:/my-git-workflow.html</id><summary type="html">&lt;h2&gt;Working Efficiently (a.k.a. Lazily)&lt;/h2&gt;
&lt;p&gt;I think it is very important to reduce the amount of typing that one has to do to keep track of projects, experiments, and working with version control, especially across multiple devices. As such, I have developed a sytem that I think works pretty …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Working Efficiently (a.k.a. Lazily)&lt;/h2&gt;
&lt;p&gt;I think it is very important to reduce the amount of typing that one has to do to keep track of projects, experiments, and working with version control, especially across multiple devices. As such, I have developed a sytem that I think works pretty well, specifically for managing Github respositories and projects directly from the command line. Though it is heavily personalized to my own Github profile and there are other tools out there like Hub, I decided to build my own. &lt;/p&gt;
&lt;p&gt;First off, I made a bash script called newRepo.sh  which will create a new repository named after the first argument that I provide after the "newRepo" command. So if I type "newRepo pytorchTutorials", I will create a new github project called pytorchTutorials that resides in my Github repositories in the cloud. This allows me to quickly create new repos and projects from the command line without having to go to the Github website, create a repository, and then clone it through the command line. The newRepo script uses the Github API to create and
clone that newly made repository as well as add a predefined project directory structure for data, notebooks, figures, and scripts. &lt;/p&gt;
&lt;p&gt;The script is still a work in progress, and I am looking to make other scripts/aliases that will allow for creating private repositories and deleting them as well. &lt;/p&gt;
&lt;p&gt;Other useful git tools that I have made are aliases for cloning, commiting, and pushing changes to the remote repository. I have 'git status' as gs, 'git add --all' as gaa, and gcp "message here" as an alias to commit all the added changes with a provided commit message, and then push the changes. &lt;/p&gt;
&lt;p&gt;This tends to speed up my workflow greatly, and I hope you can find them useful! &lt;/p&gt;
&lt;p&gt;Most of the aliases can be found in my &lt;a href="https://github.com/claytonblythe/dotfiles"&gt;dotfiles repository&lt;/a&gt; and the newRepo script can be found in my &lt;a href="https://github.com/claytonblythe/version_control"&gt;version_control&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="git"></category><category term="version control"></category><category term="bash"></category></entry><entry><title>Spark MLlib Overview</title><link href="/spark-mllib-overview.html" rel="alternate"></link><published>2017-08-30T13:10:00+00:00</published><updated>2017-08-30T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-30:/spark-mllib-overview.html</id><summary type="html">&lt;p&gt;This is an overview of the Spark MLlib framework, Spark's scalable machine learning library consisting of common machine learning algorithms and utilities that include tools for classification, regression, clustering, collaborative filtering, dimensionality reduction, as well as providing underlying basic summary statistics. It also contains various utilities for doing linear algrebra …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is an overview of the Spark MLlib framework, Spark's scalable machine learning library consisting of common machine learning algorithms and utilities that include tools for classification, regression, clustering, collaborative filtering, dimensionality reduction, as well as providing underlying basic summary statistics. It also contains various utilities for doing linear algrebra, statistics, and general handling of data. MLlib uses the linear algebra package called Breeze, which depends on the netlib-java for optimized numerical processing. Spark MLlib is distinct from Spark ML, as it deals with RDD (Resilient Distributed Datasets) instead of DataFrames. RDD's are fundamental data structures of Spark, which are divided into logical partitions and distributed across different nodes of a cluster. Spark makes use of the concept of RDD to achieve faster and more efficient MapReduce operations. It is also fault tolerant as well as in-memory data processing, which is 10 to 100 times faster than network and Disk.&lt;/p&gt;
&lt;p&gt;Here is a broad overview of the capabilities of Spark MLlib:&lt;/p&gt;
&lt;h2&gt;Basic Statistics&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Correlation&lt;/em&gt; computes the correlation matrix for the input Dataset of vectors, and the output will be a DataFrame that contains the correlation matrix of the column of vectors.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hypothesis Testing&lt;/em&gt; is possible thorugh a ChiSquare test to conduct a Pearson independence test for every feature against the label or target. For each feature, the feature label pairs are converted into a contingency matrix for which the Chi-squared statistic is computed.&lt;/p&gt;
&lt;h2&gt;ML Pipelines&lt;/h2&gt;
&lt;p&gt;Inspired by the scikit-learn project, MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline or workflow.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;DataFrame&lt;/em&gt; ML API uses DataFrame form Spark SQL as an ML dataset, which can hold a variety of data types.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Transformer&lt;/em&gt; is an algorithm that can transform one DataFrame into another DataFrame (e.g. an ML model is a Transformer which transforms a DataFrame into a DataFrame with predictions).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Estimator&lt;/em&gt; is an algorithm which can be fit on a DataFrame to produce a Transformer (this would be a learning algorithm which produces a model)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Pipeline&lt;/em&gt; chains multiple Transformers and Estimators together for a ML workflow.&lt;/p&gt;
&lt;h2&gt;Feature Selection &amp;amp; Transformation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;TF-IDF&lt;/em&gt; (Term frequency-inverse document frequency) is a feature vectorization method used in text mining to reflec thte importance of a term to a document in the corpus.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Word2Vec&lt;/em&gt; is an Estimator which takes sequences of words representing documents and trains a Word2VecModel, which maps each word to a unique fixed-size vector.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;CountVectorizer&lt;/em&gt; aim to convert a collection of text documents to vectors of token counts.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tokenizer&lt;/em&gt; is a simple class providing functionality for taking text and breaking it into individual terms (usually words), there is also RegexTokenizer which allows more advanced tokenization based on regex matching.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;StopWordsRemover&lt;/em&gt; takes an input of a sequence of strings and drops all the stop words from the input sequences.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NGram&lt;/em&gt; takes an input of a sequence of strings and the parameter n is used to determine the number of terms in each n-gram. The output will be a sequence of n-grams where each n-gram is represented by a space-delimited string of n consecutive words.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PCA&lt;/em&gt; is a statistical procedure that uses orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Polynomial Expansion&lt;/em&gt; is the process of expanding your features into a polynomial space, which is formulated by an n-degree combination of original dimensions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;OneHotEncoder&lt;/em&gt; allows for mapping a column of label indices to a column of binary vectors. This enables algorithms such as logistic regression to utilize categorical variables.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;VectorIndexer&lt;/em&gt; helps index categorical features in datasets of Vectors. It can allow algorithms such as Decision Trees and Tree Ensembles to treat categorical features appropriately, improving performance.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Interaction&lt;/em&gt; is a Transformer which takes vector or double-valued columns and can generate their interactions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Normalizer&lt;/em&gt; is a Transformer which transforms a dataset of Vector rows, normalizing each Vector to have unit norm. It takes some parameter p, which uses the p-norm used for normalization.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;StandardScaler&lt;/em&gt; transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;MinMaxScaler&lt;/em&gt; is often used to rescale a feature to a specific range like [0,1].&lt;/p&gt;
&lt;p&gt;&lt;em&gt;MaxAbsScaler&lt;/em&gt; transforms a dataset of Vector rows to a range of [-1,1].&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bucketizer&lt;/em&gt; transforms a column of continous features to a column of feature buckets.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Imputer&lt;/em&gt; is a transformer that completes missing values in a dataset, either using the mean or the median.&lt;/p&gt;
&lt;h2&gt;Feature Selectors&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;VectorSlicer&lt;/em&gt; is a transformer that takes a feature vecotr and outputs a new feature vector with a sub-array of the original features. It is useful for extracting features from a vector column.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;RFormula&lt;/em&gt; selects columns specified by an R model formula, (~, ., +, etc.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;ChiSqSelector&lt;/em&gt; uses Chi-Squared tests of independence to decide which features to use, from a fixed number of top features.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;LSH Algorithms&lt;/em&gt; like Bucketed Random Projection for Euclidian distance and MinHash for Jaccard Distance.&lt;/p&gt;
&lt;h2&gt;Classification and Regression&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Logistic Regression&lt;/em&gt; is supported with summary statistics, as well as multinomial logistic regression.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;DecisionTreeClassifier&lt;/em&gt; is a tree based calssification and regression model and so is &lt;em&gt;RandomForestClassificationModel&lt;/em&gt; and &lt;em&gt;GBTClassificationModel&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;MultilayerPerceptronClassifier&lt;/em&gt; is a classifier based on feedforward artificial neural networks, and it consists of fully connected layers that itulize a simoid logistic function and the output layer uses a softmax function. The number of nodes in the output layer corresponds to the number of classes to be classified.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;LinearSVC&lt;/em&gt; is a support vector machine that represents a hyperplane or set of hyperplanes in a high or infinite dimensional space that can be used for classification, regression, or other tasks.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NaiveBayes&lt;/em&gt; allows for simple probabilistic classifiers on applying Bayes' theorem with strong (naive) independence assumptions between the features.&lt;/p&gt;
&lt;p&gt;For regression problems, &lt;em&gt;LinearRegression&lt;/em&gt; and &lt;em&gt;GeneralizedLinearRegression&lt;/em&gt; are supported.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;AFTSurvivalRegression&lt;/em&gt; employs an Accelerated failure time (AFT) model, which is a parametric survival regression model for censored data. It is a log-linear model for survival analysis and is easier to parallelize.&lt;/p&gt;
&lt;p&gt;Other methods like ensembles of decision trees, random forest, and gradient-boosted trees are supported.&lt;/p&gt;
&lt;h2&gt;Clustering&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;K-Means&lt;/em&gt; is a popular used clustering algorithm that clusters the data points into a predefined number of clusters. The MLlib implementation includes a parallelized variant of the k-means++ method.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Latent Dirichlet Allocation&lt;/em&gt;, &lt;em&gt;Bisecting k-means&lt;/em&gt;, and &lt;em&gt;Gaussian Mixture Model (GMM)&lt;/em&gt; are all supported as well.&lt;/p&gt;
&lt;h2&gt;Collaborative Filtering&lt;/h2&gt;
&lt;p&gt;Spark MLlib supports collaborative filtering, which are techniques that aim to filll in the missing entries in a user-item association matrix. It currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. Spark.ml uses the alternating least squares algorithm to learn these latent factors.&lt;/p&gt;
&lt;h2&gt;Frequent Pattern Mining&lt;/h2&gt;
&lt;p&gt;Spark MLlib has capabilities for mining frequent items, itemsets, subsequences, or other substructures that are cmomonly the first steps for analyzing a large-scale dataset. Given a dataset of transactions, the first step is to calculate item frequencies and identify frequent items. The second step uses a suffix tree structure to encode transactions without generating candidate sets explicitly.&lt;/p&gt;
&lt;h2&gt;Model Selection&lt;/h2&gt;
&lt;p&gt;MLlib supports model selection using tools like &lt;em&gt;CrossValidator&lt;/em&gt; and &lt;em&gt;TrainValidationSplit&lt;/em&gt; which provide useful tools for hyperparameter tuning and parameter grids to search over.&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="spark"></category></entry><entry><title>CS231n Lecture 3 Notes</title><link href="/cs231n-lecture-3-notes.html" rel="alternate"></link><published>2017-08-29T13:10:00+00:00</published><updated>2017-08-29T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-29:/cs231n-lecture-3-notes.html</id><summary type="html">&lt;p&gt;I have recently been making my way through the Stanford Master's in Computer Science 231n course. This particular lecture
was about defining a loss function for how a simple Linear Classifier performs at classifying categories during training time,
and this metric in a sense quantifies how "unhappy" our scores are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have recently been making my way through the Stanford Master's in Computer Science 231n course. This particular lecture
was about defining a loss function for how a simple Linear Classifier performs at classifying categories during training time,
and this metric in a sense quantifies how "unhappy" our scores are across the training data.&lt;/p&gt;
&lt;p&gt;The task then is to find a way to efficiently find parameters (Weights and Biases) that minimize and optimize the loss function, useually via some optimization algorithm like Gradient Descent.&lt;/p&gt;
&lt;h3&gt;Loss Functions&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Multiclass SVM Loss&lt;/li&gt;
&lt;li&gt;Softmax Classifier (Cross-Entropy Loss / Multinomial Logistic Regression)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;em&gt;Multiclass SVM Loss&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The average across all the differences of the scores between the correct class and incorrect classes with a constant of one added. 1/N * Sigma { ((Incorrect class score  - Correct class score) + 1)} . Using a value of one here is
arbitrary and really just determines what magnitude the weights can be.&lt;/p&gt;
&lt;p&gt;Here when we initialize the weights, they are chosen to be small numbers, so in this case the initial value for the loss will be 2. Weight values can be multiplied in the same way, and they could be twice as large and achieve the same Loss (ignoring bias).&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Softmax Loss&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Softmax Loss is a different functional form for how loss is specified across scores. This assumes that the scores are unormalized log probabilities for each class. To get probabilities for each class,
we take the exponentiated scores for each element divided by the sum of all exponentiated elements. So here we want to maximize the log likelihood, or for a loss function we want to
minimize the negative log likelihood of the correct class. It turns out that maximizing this is more mathematically conducive than maximizing the negative probabilities themselves.
For the example of classifying a cat, if the normalized probability of a cat class is .13 then the loss would be -log(.13)= .89, and we are trying to maximize this, where zero is the minimum and there is no bounded maximum.&lt;/p&gt;
&lt;p&gt;When we initialize weights we typically choose them to be very small, so there should be an initial loss of -log( 1 / number of classes), as the initial scores would be zero, then unormalized probabilities of 1 for every class, then
the loss should be -log( 1 / # of classes ). As the model trains, the loss should move toward zero.&lt;/p&gt;
&lt;p&gt;Optimization occurs by finding the gradient of the loss function with respect to certain parameters, usually the weights for each class. In practice an analytic gradient is used, which is an exact, fast, but error-prone method.
You often then do a gradient check, where you compare the numerical gradient which is usually approximate, slow, but easy to write compared to your analytic gradient.&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Weight Regularization&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Weight regularization is a set of techniques to add objectives to the loss function, such that there exists a tradeoff between training error and generalization error. 
The most common form of regularization in neural networks is L2 regularization, also known as weight decay. This push$
Therefore regularization loss is a new component that contributes to the overall loss, and it is only a function of 
Including this weight regularization in the overall loss function that you are trying to minimize leads to weights that are diffuse, making sure that the network does not overfit certain regions of the image. This leads to better generalization performance at testing time.&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Stochastic Gradient Descent&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;This process is usually composed of two steps:
  1. Find the weights gradient by evaluating the gradient of the loss function with respect to the parameters of your training data, the weights. 
  2. Set new weights by multiplying step size (a.k.a. learning rate) by the gradient of the loss function with respect to weights, most importantly in the direction of the negative gradient. The gradient points in the direction of maximal increase, so the negative gradient will modify the parameters of the network closer to minimizing the loss function, or at least moving toward some local minimum.&lt;/p&gt;
&lt;p&gt;The learning rate/step size is an important hyperparameter for this.&lt;/p&gt;
&lt;h3&gt;&lt;em&gt;Mini-batch Gradient Descent&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Instead of using all training samples for each iteration (finding the gradient of the loss function corresponding to all your training data), you can use a small &lt;em&gt;batch&lt;/em&gt; comprised of a small subset of your training data. Then you can get a good approximation of the gradient and use smaller step sizes rather than using a full-batch size for each iteration or epoch.
Often this isn't a very significant hyperparameter to tune, but rather you choose this based on your GPU architecture and the constraints of your memory.
The key is finding the appropriate learning rate to converge over time across epochs (full cycles through your training data).&lt;/p&gt;
&lt;p&gt;The loss function can be thought of as an optimization problem in high-dimensional space, in which we are trying to reach the bottom of some high-dimensional valley. We start with some random initialization of weights and through iterative differentiation and adjustment we can reach the bottom. The next important concept to cover will be backprogation, essentially how to compute the gradient analytically by using the chain rule. &lt;/p&gt;
&lt;p&gt;The advancements recently (since roughly 2012) of using these techniques for neural networks are that you do not have to hand-craft features regarding your images, but rather you can train your entire network and the network automatically learns feature
without explicitly being programmed the structure of features or objects, like most rule-based recognition systems of the past were. Here the networks can be trained all the way back to the raw pixels, which make them very powerful and flexible at solving a wide array of problems in sound, image, and pattern recognition.&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="cs231n"></category><category term="notes"></category><category term="python"></category><category term="neural networks"></category></entry><entry><title>Single-Shot Detector Prototype</title><link href="/single-shot-detector-prototype.html" rel="alternate"></link><published>2017-08-29T13:10:00+00:00</published><updated>2017-08-29T13:10:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-29:/single-shot-detector-prototype.html</id><summary type="html">&lt;p&gt;I have wanted to experiment with multibox object detection and semantic segmentation in urban environments, so I started this very rough prototyping project for implementing SSD (Single-Shot Detector) in an urban environment, to detect things like pedestrians, bikes, cars, and buses. The SSD model is known for being fast at …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have wanted to experiment with multibox object detection and semantic segmentation in urban environments, so I started this very rough prototyping project for implementing SSD (Single-Shot Detector) in an urban environment, to detect things like pedestrians, bikes, cars, and buses. The SSD model is known for being fast at inference time and it performs object localization and classification in one pass. Also, I could readily find examples written in PyTorch on github &lt;a href="https://github.com/amdegroot/ssd.pytorch"&gt;here&lt;/a&gt;. I used this repository heavily, and
started my own project to run an SSD network on a &lt;a href="https://www.youtube.com/watch?v=Kk26RfjhFz0"&gt;4k video&lt;/a&gt; of someone walking through Times Square in New York. I figured that it would be a good opportunity to experiment with these types of networks in a real-world environment. &lt;/p&gt;
&lt;p&gt;Here is an example of an image in Times Square to classify. You can see there are pictures of various people walking around, including a couple people in Elmo costumes! &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="http://deepython.com/images/elmo.png"&gt;&lt;/p&gt;
&lt;p&gt;Here is the downsampled images preprocessed with subracted mean for SSD. This type of preprocessing is typical for these types of image processing tasks.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="http://deepython.com/images/condensed_rgb_elmo.png"&gt;&lt;/p&gt;
&lt;p&gt;Here is the final result with bounding boxes and entity classification! I think it does a pretty darn good job at classification, even on the people in Elmo costumes.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Test" src="http://deepython.com/images/elmo_boxed.png"&gt;&lt;/p&gt;
&lt;p&gt;I think this was a fun prototype for me to get my feet wet a little bit. It is pretty slow even on GPU, as I am using a pretty verbose PyTorch script and using the PIL image library which adds a fair amount of overhead. &lt;/p&gt;
&lt;p&gt;Next, I plan on writing a python script to pipe frames from ffmpeg to create classification bounding boxes. I also plan on experimenting with more compact model architectures like SqueezeNet. &lt;a href="https://github.com/claytonblythe/citywatch"&gt;Here&lt;/a&gt; is my Github repo if you want to take a look. &lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content></entry><entry><title>Docker 101</title><link href="/docker-101.html" rel="alternate"></link><published>2017-08-18T22:34:00+00:00</published><updated>2017-08-18T22:34:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-18:/docker-101.html</id><summary type="html">&lt;p&gt;This is a post about what Docker is, and how you can use it to be more efficient in your work, especially if it involves deploying to production or sharing with others. With machine learning and deep learning, it can be difficult to keep all the dependencies straight, especially with …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a post about what Docker is, and how you can use it to be more efficient in your work, especially if it involves deploying to production or sharing with others. With machine learning and deep learning, it can be difficult to keep all the dependencies straight, especially with diverging distributions and versions of linux, python, or various packages. &lt;/p&gt;
&lt;p&gt;Over the past few years, tools like virtual machines or virtual envrionments have become more popular for developing ephemeral environments for doing reproducible research and deployment (DevOps). With Docker, an &lt;em&gt;image&lt;/em&gt; can be specified, which is essentially a blueprint for an isolated environment
 called a container, which runs on top of &lt;em&gt;nearly&lt;/em&gt; any operating system. With Docker, it is possible to use these images to create &lt;em&gt;containers&lt;/em&gt; which are launched and allow for you to specify exactly what type of operating system, language iteration, and software it contains. &lt;/p&gt;
&lt;p&gt;Docker containers are useful as a layer that makes Linux containers easier to use. It is also OS agnostic, so you can use these images to make docker containers on various systems whether they are Mac, Windows, or Linux. &lt;/p&gt;
&lt;p&gt;So say you want to share a PyTorch project that you worked on a few weeks ago, and others need the ability to quickly reproduce your work, or maybe you need to launch it as some type of service. With Docker images and containers, they can be quickly spun up and more importantly they are reliable and just work. This is where Docker containers become very useful. &lt;/p&gt;
&lt;p&gt;One use that I frequently use Docker for is launching a Pytorch Jupyter Notebook server that can run on nearly any environment. Here I can quickly launch new experiments, make commits to git repositories when I make progress, and just remove the container at the end without being worried about reproducing some working environment for later use. &lt;/p&gt;
&lt;p&gt;Another use that I find useful is for reproducing a personalized environment with your own bash aliases and profile, Github repositories and basic software. I have a Dockerfile that runs vanilla ubuntu with basic things like conda, python3.6, git, vim, pip, and pelican. Then it clones Github repositories for projects that I am frequently working on, and my personalized dotfiles (.bashrc .bash_profile .aliases), vim configuration. So in a sense, my personal computer and working environment lives in a version controlled environment specified by a docker image "recipe".
Should somthing go wrong with certain libraries or configurations, I can almost instsantly reproduce a base personalized working environment almost instantly. This allows me to be comfortable working on any machine with Docker installed, as I can quickly reproduce my desired and personalized most up-to-date environment. &lt;/p&gt;
&lt;p&gt;Examples of this can be found on my Github profile in the &lt;a href="https://github.com/claytonblythe/Dockerfiles"&gt;dockerfiles repository&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="docker"></category><category term="version control"></category></entry><entry><title>Personalized Bash Environment</title><link href="/personalized-bash-environment.html" rel="alternate"></link><published>2017-08-18T22:34:00+00:00</published><updated>2017-08-18T22:34:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-18:/personalized-bash-environment.html</id><summary type="html">&lt;h2&gt;Understanding Bash Startup Files&lt;/h2&gt;
&lt;p&gt;In order to do efficient work in a unix/linux environment, it is important to get a personalized environment setup to use various aliases, navigate to default directories, and to get your proper path environment setup. This article is meant to summarize the difference between .bashrc …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Understanding Bash Startup Files&lt;/h2&gt;
&lt;p&gt;In order to do efficient work in a unix/linux environment, it is important to get a personalized environment setup to use various aliases, navigate to default directories, and to get your proper path environment setup. This article is meant to summarize the difference between .bashrc, .bash_profile, and .profile files and what I think the best setup is regarding these files. It is standard for these files to be stored in the home directory '~', which is the  &lt;a href="https://www.gnu.org/software/bash/manual/bashref.html#Tilde-Expansion"&gt;Tilde Expansion&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;It's helpful to think about how Bash chronologically behaves when it is invoked as a interactive login session. When Bash is invoked as interactive, it first reads from the file /etc/profile if that file exists. After reading that file, it will look for a file at ~/.bash_profile, ~/.bash_login, and ~/.profile in that order. It will execute commands from the first one that is available if it exists, and it will not proceed unless explicitly told so. &lt;/p&gt;
&lt;p&gt;If Bash is invoked as an interactive non-login session, then Bash reads and executes commands from ~/.bashrc if that file exists. Therefore, it is common to include the following commands in ~/.bash_profile, as it is often desired to ensure that ~/.bashrc is executed regardless of whether Bash is executed in a login or non-login session.  &lt;/p&gt;
&lt;p&gt;if [ -f ~/.bashrc ]; then
   source ~/.bashrc
fi&lt;/p&gt;
&lt;p&gt;So here in ~/.bashrc you can put all various starting configurations like your environment's PATH, and you can source a file containing aliases, like mine is at ~/.aliases. So every time you have a terminal session, whether it is a login session or simply another window, you can have your personalized environment ready for you. &lt;/p&gt;
&lt;p&gt;Just to specify, for remote shell logins, like a ssh login, Bash will read /etc/profile and then one of ~/.bash_profile or ~/.profile. &lt;/p&gt;
&lt;p&gt;For more reading, you can visit the bash manual and user guide &lt;a href="https://www.gnu.org/software/bash/manual/bashref.html#Introduction"&gt;here&lt;/a&gt;, or you can see another helpful guide &lt;a href="https://mywiki.wooledge.org/DotFiles"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I think my setup will most likely include a sourcing of aliases from ~/.aliases within my ~/.bashrc file, which is sourced for every terminal session, either login or non-login sessions. This seems to be a good setup for keeping things tidy and organized. I am open to suggestions and advice if anyone reads this post!&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="bash"></category><category term="version control"></category></entry><entry><title>Deep Learning 101: A Brief Introduction</title><link href="/deep-learning-101-a-brief-introduction.html" rel="alternate"></link><published>2017-08-18T22:19:00+00:00</published><updated>2017-08-18T22:19:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-18:/deep-learning-101-a-brief-introduction.html</id><summary type="html">&lt;p&gt;So you want to learn about Deep Learning huh?&lt;/p&gt;
&lt;p&gt;Well I'm not sure I'm quite qualified yet, as I just started learning about this myself. But the best way to learn something is to try to teach it to other people, so here I am. I hope you find this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So you want to learn about Deep Learning huh?&lt;/p&gt;
&lt;p&gt;Well I'm not sure I'm quite qualified yet, as I just started learning about this myself. But the best way to learn something is to try to teach it to other people, so here I am. I hope you find this post and blog useful.&lt;/p&gt;
&lt;p&gt;To begin our understanding of this field, we need to introduce the topic of machine learning. &lt;a href="https://www.wikiwand.com/en/Machine_learning"&gt;Machine Learning&lt;/a&gt; is the ability of a computer to aquire knowledge and make predictions through extracting latent patterns and information from data. Machine Learning can almost be thought of as a form of applied statistics, in which computers statistically estimate some function. Within machine learning, problems can usually be broken down into &lt;a href="https://www.wikiwand.com/en/Supervised_learning"&gt;supervised learning&lt;/a&gt; and &lt;a href="https://www.wikiwand.com/en/Unsupervised_learning"&gt;unsupervised learning&lt;/a&gt;. The former infers or approximates some function from labeled training data, where the function represents a relationship between input variables (often called features) and a labeled or known output value. In unsupervised learning, the task is to describe the hidden structure and properties of input data without explicitly being given labeled training data. Within machine learning there is a subdomain called &lt;a href="https://www.wikiwand.com/en/Deep_learning"&gt;Deep Learning&lt;/a&gt;, and this area will be the primary focus of this blog, &lt;a href="https://deepython.com"&gt;&lt;em&gt;Deep Python&lt;/em&gt;&lt;/a&gt; @ &lt;a href="https://deepython.com"&gt;&lt;em&gt;deepython.com&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A couple fundamental concepts in deep learning are Artificial Neural Networks and Convolutional Neural Networks.&lt;/p&gt;
&lt;h2&gt;Key concepts:&lt;/h2&gt;
&lt;h3&gt;1. Artificial Neural Networks&lt;/h3&gt;
&lt;h3&gt;2. Convolutional Recurrent Neural Networks (CNNs)&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.wikiwand.com/en/Artificial_neural_network"&gt;Artificial Neural Networks&lt;/a&gt; are systems created by modern computing systems created to complete complex tasks such as image and sound recognition. They were inspired by traditional biological networks, which are adept at completing complex tasks like recognizing faces, understanding audible speech, or translating one written language into another. The important thing is that these tasks are extremely difficult to formalize into traditional rule-based systems, and hence these problems have seen large progress through the development of neural networks.  &lt;/p&gt;
&lt;p&gt;This is the most promising and conceptually difficult area of machine learning, as it requires employing linear algebra along with modern GPU architecture to create a complex network of connected neurons which allow computers to learn complex patterns from experiences, and to solve problems through breaking tasks down into simpler, more manageable components. This is done by stacking several "layers" of mathematical operations and transformations on top of one another, hence the field's buzzword
&lt;em&gt;Deep Learning&lt;/em&gt; and the name of my blog &lt;em&gt;Deep Python&lt;/em&gt; @ &lt;a href="http://deepython.com"&gt;&lt;em&gt;deepython.com&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.wikiwand.com/en/Convolutional_neural_network"&gt;Convolutional Neural Networks&lt;/a&gt; then are an extension of Artificial Neural Networks, which use a variation of &lt;a href="https://www.wikiwand.com/en/Multilayer_perceptron"&gt;multi-layer perceptrons&lt;/a&gt; and require minimal preprocessing of the data. &lt;a href="https://www.wikiwand.com/en/Multilayer_perceptron"&gt;Multi-layer perceptrons&lt;/a&gt; are mathematical expressions that map some set of input values to output values. As a whole, Convolutional Neural Networks usually have an input layer, several hidden layers, and an output layer. These layers can be convolutional, pooling, or fully connected as a traditional multi-layer perceptron network would be. As is standard, these networks employ &lt;a href="https://www.wikiwand.com/en/Backpropagation"&gt;backpropagation&lt;/a&gt; to calculate the error each neuron contributes to the network's discriminatory ability, through calculating the &lt;a href="https://www.wikiwand.com/en/Gradient"&gt;gradient&lt;/a&gt; of the loss function. A gradient can be though of as a mathematical operation that finds the direction of maximal increase (consequently the opposite direction is  used for minimization). Throughout these layers, there are parameters called biases and weights that represent the underlying mathematical operations of matrix multiplication. Then, these weights and biases are used to calculate some set of final values, often scores for different classes. These cores are then mapped to a loss function that represent's error in the network's discriminatory ability. &lt;/p&gt;
&lt;p&gt;The most commonly used loss function is the &lt;a href="https://www.wikiwand.com/en/Loss_functions_for_classification#/Cross_entropy_loss"&gt;cross entropy loss function&lt;/a&gt;. Then, an optimization algorithm such as &lt;a href="https://www.wikiwand.com/en/Gradient_descent"&gt;gradient descent&lt;/a&gt; is used to modify weights and biases to iteratively move toward the minimum of the loss function at some previously defined learning rate.&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;Convolutional Neural Networks&lt;/em&gt; (CNN's)&lt;/h2&gt;
&lt;p&gt;Convolutional Neural Networks have been found to greatly improve classification accuracy for &lt;a href="https://www.wikiwand.com/en/Convolutional_neural_network#/Applications"&gt;complex tasks&lt;/a&gt; such as image classification, facial recognition, natural language processing, drug discovery, and are even beating humans at complex games such as Go. In fact, competing against humans in video games such as Starcraft and Dota2 is an active area of research in deep learning, as it requires a high number of dimensions to represent a game at a given instant.  &lt;/p&gt;
&lt;p&gt;So the &lt;em&gt;deepness&lt;/em&gt; in &lt;a href="https://www.wikiwand.com/en/Deep_learning"&gt;&lt;em&gt;Deep Learning&lt;/em&gt;&lt;/a&gt;  is a term that typically refers to neural networks that employ many layers of neurons like multi-layer peceptrons or &lt;a href="https://www.wikiwand.com/en/Sigmoid_function"&gt;sigmoid neurons&lt;/a&gt; for feature extraction and learning. They take raw, base level information such as the brightness of individual pixels in an image, and add layers that progressively accumulate more complex information like edges, shapes, groups of shapes, and faces. Neural Networks employ these techniques to solve difficult and nebulous problems by breaking them down into a hierarchy of components that gradually increase in complexity. As mentioned previously, these networks are particularly useful in  &lt;a href="https://www.wikiwand.com/en/Unsupervised_learning"&gt;unsupervised learning&lt;/a&gt;, in which the representation of the data is learned from scratch by the network itself. This is an important emerging area of research, as the vast majority of data being produced in the world is unlabeled, such as the sentiment of reddit comments, or audio that does not have transcription available.&lt;/p&gt;
&lt;p&gt;Overall, this is an exciting area that I am looking forward to learning more about, and this is just a high-level overview of the basics.&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="python"></category><category term="neural networks"></category><category term="intro"></category></entry><entry><title>Introducing Deep Python</title><link href="/introducing-deep-python.html" rel="alternate"></link><published>2017-08-13T15:01:00+00:00</published><updated>2017-08-13T15:01:00+00:00</updated><author><name></name></author><id>tag:None,2017-08-13:/introducing-deep-python.html</id><summary type="html">&lt;p&gt;Python(noun) : &lt;em&gt;A large heavy-bodied nonvenomous constrictor snake occurring throughout the Old World tropics.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;...Sorry to get your hopes up, but this won't be a discussion about snakes nor the reptilian overlords that run the U.S government.&lt;/p&gt;
&lt;p&gt;Instead, this is the first post of my new blog called &lt;em&gt;Deep …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Python(noun) : &lt;em&gt;A large heavy-bodied nonvenomous constrictor snake occurring throughout the Old World tropics.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;...Sorry to get your hopes up, but this won't be a discussion about snakes nor the reptilian overlords that run the U.S government.&lt;/p&gt;
&lt;p&gt;Instead, this is the first post of my new blog called &lt;em&gt;Deep Python&lt;/em&gt; @ &lt;a href="http://deepython.com"&gt;deepython.com&lt;/a&gt;. I am writing this blog as a hobby, as I begin my own personal learning adventure and career in the domain of neural networks, deep learning, and
artificial intelligence. I plan to use this as an outreach avenue, but also as a knowledge repository for myself and others too.&lt;/p&gt;
&lt;p&gt;Just so you know what's to come, the blog will cover a wide range of topics that describe projects that I take on for fun, and I might even write about some miscellaneous topics as well. I imagine that I will cover relevant topics like &lt;a href="https://www.wikiwand.com/en/Python_programming_language"&gt;Python&lt;/a&gt;, &lt;a href="https://www.wikiwand.com/en/Torch_machine_learning"&gt;Pytorch&lt;/a&gt;, &lt;a href="https://www.wikiwand.com/en/TensorFlow"&gt;TensorFlow&lt;/a&gt;, &lt;a href="https://www.wikiwand.com/en/Linux"&gt;Linux&lt;/a&gt;, &lt;a href="https://www.google.com/search?q=pyspark&amp;amp;oq=pyspark&amp;amp;aqs=chrome..69i57j0l5.750j0j4&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8"&gt;Spark&lt;/a&gt;, &lt;a href="https://www.wikiwand.com/en/Git"&gt;Git&lt;/a&gt;, &lt;a href="http://pokemon.wikia.com/wiki/Vulpix"&gt;Vulpix&lt;/a&gt; and &lt;a href="https://www.wikiwand.com/en/Docker_software"&gt;Docker&lt;/a&gt;... Now which one of those was a pokemon? &lt;/p&gt;
&lt;p&gt;Joking aside, don't be surprised at an occasional excursion into economics, current news, or personal finance.
Anyways, I think that is long enough for my first post. I'll keep it short and sweet, but be sure that I have quite a few ideas for posts to come!&lt;/p&gt;
&lt;p&gt;Feel free to send me an email at &lt;a href="mailto:claytondblythe@gmail.com"&gt;claytondblythe@gmail.com&lt;/a&gt; if you have ideas for projects, posts, or suggestions for improvement.&lt;/p&gt;
&lt;p&gt;Until next time,&lt;/p&gt;
&lt;h4&gt;Clayton Blythe | &lt;em&gt;Deep Python&lt;/em&gt;&lt;/h4&gt;</content><category term="introduction"></category><category term="python"></category></entry></feed>