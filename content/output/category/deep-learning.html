<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>A Pelican Blog - Deep Learning</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="A Pelican Blog Atom Feed" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">A Pelican Blog </a></h1>
                <nav><ul>
                    <li class="active"><a href="/category/deep-learning.html">Deep Learning</a></li>
                    <li><a href="/category/docker.html">Docker</a></li>
                    <li><a href="/category/misc.html">Misc</a></li>
                    <li><a href="/category/other.html">Other</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/neural-selfie.html">Neural Selfie</a></h1>
<footer class="post-info">
        <abbr class="published" title="2017-10-02T13:10:00+00:00">
                Published: Mon 02 October 2017
        </abbr>

<p>In <a href="/category/deep-learning.html">Deep Learning</a>.</p>

</footer><!-- /.post-info --><p>I recently have been trying to learn PyTorch, as it is becoming more popular for machine learning researchers because of its ability to represent complex neural network architectures in just a few lines of code. It also allows for dynamic definition of graphs, unlike its main competitor TensorFlow. This becomes very useful for working with Recurrent Neural Networks for example. </p>
<p>For this post, I implement the Neural Style Transfer algorithm in <a href="https://arxiv.org/abs/1508.06576">this paper</a> that takes a content image and a style image and returns a version of that content image with the appropriate "style". </p>
<p>The main idea is that two distances are defined for the content and one for the style. The goal is to transform the image to minimize both the content distance with respect to the content image and vice versa for the style image. </p>
<p>In the implementation described in the <a href="http://pytorch.org/tutorials/advanced/neural_style_tutorial.html">PyTorch Documentation</a> a pretrained VGG convolutional neural network is used as a base starting point. The content distance is defined as the sum of all squared differences between the feature maps at each Lth layer of the content and produced images, for every ith element of that layer's feature map.</p>
<p>The style distance is more obscure, using a Gram produce of vectorized feature maps, representing the correlation between feature maps at some layer for both style and output images. The gradients for both distances/losses are calculated and summed together, and then backpropagation is done. </p>
<p>For example, we can do style transfer of "Starry Night" onto a selfie of myself. </p>
<p><img alt="Alt Test" src="https://deepython.com/images/starrynight.png">
<img alt="Alt Test" src="https://deepython.com/images/headshot.png"></p>
<p>And here is the result: 
<img alt="Alt Test" src="https://deepython.com/images/starryn_cw0.6.png"></p>
<p>I think that the results are pretty amazing to be honest, however it should be noted that I ran hundreds of different weight combinations for different images, and hand-picked the best results to post on here. I think it has produced some interesting pictures that I plan to use on for online profile pictures. </p>
<p>Here are a couple more results. The first was created using a green spider-web looking image, and the second with the famous "Scream" painting. </p>
<p><img alt="Alt Test" src="https://deepython.com/images/trial_19642857_3.8.png"></p>
<p><img alt="Alt Test" src="https://deepython.com/images/trial_6957597_0.2.png"></p>
<p>Overall, I had a blast working on this project. It was a great opportunity for me to experiment with neural networks and PyTorch. I'm looking forward to learning more! </p>
<p>Until next time,</p>
<h4>Clayton Blythe | <em>Deep Python</em></h4>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="/cs231n-lecture-5-notes.html" rel="bookmark"
                           title="Permalink to CS231n Lecture 5 Notes">CS231n Lecture 5 Notes</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-09-13T13:10:00+00:00">
                Published: Wed 13 September 2017
        </abbr>

<p>In <a href="/category/deep-learning.html">Deep Learning</a>.</p>
<p>tags: <a href="/tag/cs231n.html">cs231n</a> <a href="/tag/python.html">python</a> <a href="/tag/notes.html">notes</a> <a href="/tag/neural-networks.html">neural networks</a> </p>
</footer><!-- /.post-info -->                <p>The purpose of this lecture was to introduce neural networks, and it extends beyond linear classification and describes how the "wiggle" (non-linearity) of neural networks are generated. The calculation of a score formula s=Wx is extended to add a clamping function like max(0, W1x) where an arbitrary number …</p>
                <a class="readmore" href="/cs231n-lecture-5-notes.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/cs231n-lecture-4-notes.html" rel="bookmark"
                           title="Permalink to CS231n Lecture 4 Notes">CS231n Lecture 4 Notes</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-09-03T13:10:00+00:00">
                Published: Sun 03 September 2017
        </abbr>

<p>In <a href="/category/deep-learning.html">Deep Learning</a>.</p>
<p>tags: <a href="/tag/cs231n.html">cs231n</a> <a href="/tag/python.html">python</a> <a href="/tag/notes.html">notes</a> <a href="/tag/neural-networks.html">neural networks</a> </p>
</footer><!-- /.post-info -->                <p>The purpose of this lecture was to introduce the imporatance and basic functioning of an fundamental concept in neural networks, backprogation. In short, backpropagation is a method for computing the gradient of a loss function with respect to the weights and biases of a neural network. This is done through …</p>
                <a class="readmore" href="/cs231n-lecture-4-notes.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/cs231n-lecture-3-notes.html" rel="bookmark"
                           title="Permalink to CS231n Lecture 3 Notes">CS231n Lecture 3 Notes</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-08-29T13:10:00+00:00">
                Published: Tue 29 August 2017
        </abbr>

<p>In <a href="/category/deep-learning.html">Deep Learning</a>.</p>
<p>tags: <a href="/tag/cs231n.html">cs231n</a> <a href="/tag/notes.html">notes</a> <a href="/tag/python.html">python</a> <a href="/tag/neural-networks.html">neural networks</a> </p>
</footer><!-- /.post-info -->                <p>I have recently been making my way through the Stanford Master's in Computer Science 231n course. This particular lecture
was about defining a loss function for how a simple Linear Classifier performs at classifying categories during training time,
and this metric in a sense quantifies how "unhappy" our scores are …</p>
                <a class="readmore" href="/cs231n-lecture-3-notes.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/single-shot-detector-prototype.html" rel="bookmark"
                           title="Permalink to Single-Shot Detector Prototype">Single-Shot Detector Prototype</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-08-29T13:10:00+00:00">
                Published: Tue 29 August 2017
        </abbr>

<p>In <a href="/category/deep-learning.html">Deep Learning</a>.</p>

</footer><!-- /.post-info -->                <p>I have wanted to experiment with multibox object detection and semantic segmentation in urban environments, so I started this very rough prototyping project for implementing SSD (Single-Shot Detector) in an urban environment, to detect things like pedestrians, bikes, cars, and buses. The SSD model is known for being fast at …</p>
                <a class="readmore" href="/single-shot-detector-prototype.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/deep-learning-101-a-brief-introduction.html" rel="bookmark"
                           title="Permalink to Deep Learning 101: A Brief Introduction">Deep Learning 101: A Brief Introduction</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-08-18T22:19:00+00:00">
                Published: Fri 18 August 2017
        </abbr>

<p>In <a href="/category/deep-learning.html">Deep Learning</a>.</p>
<p>tags: <a href="/tag/python.html">python</a> <a href="/tag/neural-networks.html">neural networks</a> <a href="/tag/intro.html">intro</a> </p>
</footer><!-- /.post-info -->                <p>So you want to learn about Deep Learning huh?</p>
<p>Well I'm not sure I'm quite qualified yet, as I just started learning about this myself. But the best way to learn something is to try to teach it to other people, so here I am. I hope you find this …</p>
                <a class="readmore" href="/deep-learning-101-a-brief-introduction.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
                </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>